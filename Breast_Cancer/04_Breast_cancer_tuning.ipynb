{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_cancer_tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Raol13zOa7YN",
        "outputId": "7affd783-0b6c-4f39-8308-c7fe02296a8c"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "uploaded =files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5f57e91b-ca1e-4ea4-a92b-4612408dd18e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5f57e91b-ca1e-4ea4-a92b-4612408dd18e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving entradas_breast.csv to entradas_breast.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "byMgNr9YbHTY",
        "outputId": "411541b4-422e-466b-f9ef-db5bc038d951"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "  \n",
        "previsores = pd.read_csv(io.BytesIO(uploaded['entradas_breast.csv']))\n",
        "previsores"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.00000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>205.00000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>111.00000</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1176.0000</td>\n",
              "      <td>1256.0000</td>\n",
              "      <td>7673.0</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.45</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>141.00000</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>206.0000</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>144.00000</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2463.0000</td>\n",
              "      <td>5203.0</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.69</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>159.0000</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1075.0000</td>\n",
              "      <td>3425.0</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.98</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>277.00000</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>152.00000</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>726.0000</td>\n",
              "      <td>1595.0000</td>\n",
              "      <td>5772.0</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.74</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>165.00000</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>265.0000</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>124.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1428.0000</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9456.00</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0           17.99          10.38  ...           0.4601                   0.11890\n",
              "1           20.57          17.77  ...         275.0000                   0.08902\n",
              "2           19.69          21.25  ...           0.3613                   0.08758\n",
              "3           11.42          20.38  ...           0.6638                 173.00000\n",
              "4           20.29          14.34  ...           0.2364                   0.07678\n",
              "..            ...            ...  ...              ...                       ...\n",
              "564         21.56          22.39  ...         206.0000                   0.07115\n",
              "565         20.13          28.25  ...           0.2572                   0.06637\n",
              "566         16.60          28.08  ...           0.2218                   0.07820\n",
              "567         20.60          29.33  ...           0.4087                 124.00000\n",
              "568          7.76          24.54  ...           0.2871                   0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "NuUkpAI7bNCj",
        "outputId": "e78cf80a-6ff1-4455-baf7-9035a650e465"
      },
      "source": [
        "uploaded =files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-05432c9d-e21c-4e88-9b09-d1dae6bb10c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-05432c9d-e21c-4e88-9b09-d1dae6bb10c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving saidas_breast.csv to saidas_breast.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoFEd3c7bRfq"
      },
      "source": [
        "classe = pd.read_csv(io.BytesIO(uploaded['saidas_breast.csv']))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMCD5ijDbfjY"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def criarRede(optimizer, loss, kernel_initializer, activation, neurons):\n",
        "  classificador=Sequential()\n",
        "#Primeira camada oculta\n",
        "#Definição da primeira camada de entrada (input_dim)\n",
        "  classificador.add(Dense(units =neurons, activation= activation, kernel_initializer=kernel_initializer, input_dim=30)) \n",
        "#camada de dropout, passando o parametro da porcentagem que eu quero zerar\n",
        "  classificador.add(Dropout(0.2))\n",
        "#Segunda camada oculta  \n",
        "  classificador.add(Dense(units =neurons, activation= activation, kernel_initializer=kernel_initializer)) \n",
        "  classificador.add(Dropout(0.2))\n",
        "#camada de saida\n",
        "  classificador.add(Dense(units =1, activation= 'sigmoid'))   \n",
        "#classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "  classificador.compile(optimizer=optimizer, loss=loss, metrics=['binary_accuracy'])\n",
        "  return classificador"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_uJIAMmh0dr"
      },
      "source": [
        "classificador = KerasClassifier(build_fn =criarRede)\n",
        "parametros={'batch_size': [10,30],\n",
        "            'epochs' : [50,100],\n",
        "            'optimizer': ['adam','sgd'],\n",
        "            'loss' : ['binary_crossentropy', 'hinge'],\n",
        "            'kernel_initializer': ['random_uniform','normal'],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'neurons': [16,8]}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK_esjYk6Oxt",
        "outputId": "b1f08db5-60bb-48a4-8e5f-4a16ef7d19fb"
      },
      "source": [
        "\n",
        "grid_search=GridSearchCV(estimator=classificador,\n",
        "                         param_grid=parametros, \n",
        "                         scoring='accuracy', \n",
        "                         cv=5)\n",
        "grid_search=grid_search.fit(previsores,classe)\n",
        "melhores_parametros=grid_search.best_params_\n",
        "melhor_precisao=grid_search.best_score_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.6806 - binary_accuracy: 0.5538\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6695 - binary_accuracy: 0.5978\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6735 - binary_accuracy: 0.6132\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6668 - binary_accuracy: 0.6242\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6653 - binary_accuracy: 0.6198\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6731 - binary_accuracy: 0.6396\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6663 - binary_accuracy: 0.6330\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6552 - binary_accuracy: 0.6418\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6542 - binary_accuracy: 0.6440\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6581 - binary_accuracy: 0.6440\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6613 - binary_accuracy: 0.6418\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6674 - binary_accuracy: 0.6418\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6493 - binary_accuracy: 0.6418\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6555 - binary_accuracy: 0.6396\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6565 - binary_accuracy: 0.6396\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6638 - binary_accuracy: 0.6418\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6508 - binary_accuracy: 0.6440\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6504 - binary_accuracy: 0.6440\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6573 - binary_accuracy: 0.6418\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6501 - binary_accuracy: 0.6396\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6506 - binary_accuracy: 0.6418\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6516 - binary_accuracy: 0.6418\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6501 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6549 - binary_accuracy: 0.6418\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6524 - binary_accuracy: 0.6418\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6571 - binary_accuracy: 0.6418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6563 - binary_accuracy: 0.6418\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.6418\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - binary_accuracy: 0.6418\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6374\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6516 - binary_accuracy: 0.6440\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6476 - binary_accuracy: 0.6374\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.6462\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6549 - binary_accuracy: 0.6396\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6481 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6534 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6374\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - binary_accuracy: 0.6396\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - binary_accuracy: 0.6440\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6494 - binary_accuracy: 0.6418\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.6396\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6418\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6533 - binary_accuracy: 0.6462\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6467 - binary_accuracy: 0.6440\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6599 - binary_accuracy: 0.6286\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.6418\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.6352\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6412 - binary_accuracy: 0.6330\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6459 - binary_accuracy: 0.6549\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6501 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6451 - binary_accuracy: 0.6440\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6451 - binary_accuracy: 0.6396\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6400 - binary_accuracy: 0.6374\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6375 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6455 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6392 - binary_accuracy: 0.6462\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6396\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6526 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6416 - binary_accuracy: 0.6352\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6549 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6496 - binary_accuracy: 0.6352\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6374\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - binary_accuracy: 0.6308\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - binary_accuracy: 0.6308\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.6396\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6470 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.6484\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6410 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6436 - binary_accuracy: 0.6396\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6374\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6436 - binary_accuracy: 0.6440\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6398 - binary_accuracy: 0.6462\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6533 - binary_accuracy: 0.6440\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6456 - binary_accuracy: 0.6352\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6430 - binary_accuracy: 0.6484\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6465 - binary_accuracy: 0.6330\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6532 - binary_accuracy: 0.6440\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - binary_accuracy: 0.6242\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6323 - binary_accuracy: 0.6396\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.6440\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6346 - binary_accuracy: 0.6396\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6472 - binary_accuracy: 0.6374\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6495 - binary_accuracy: 0.6440\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6410 - binary_accuracy: 0.6484\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6467 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6426 - binary_accuracy: 0.6308\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6357 - binary_accuracy: 0.6308\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.6396\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6411 - binary_accuracy: 0.6308\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.6396\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6312 - binary_accuracy: 0.6396\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6502 - binary_accuracy: 0.6330\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6449 - binary_accuracy: 0.6440\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6475 - binary_accuracy: 0.6396\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6486 - binary_accuracy: 0.6352\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6352 - binary_accuracy: 0.6396\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6885 - binary_accuracy: 0.5319\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6794 - binary_accuracy: 0.5692\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6700 - binary_accuracy: 0.6132\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6709 - binary_accuracy: 0.6242\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6706 - binary_accuracy: 0.6132\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6693 - binary_accuracy: 0.5978\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6635 - binary_accuracy: 0.6088\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.6110\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6579 - binary_accuracy: 0.6242\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6562 - binary_accuracy: 0.6220\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6580 - binary_accuracy: 0.6198\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6539 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6532 - binary_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6558 - binary_accuracy: 0.6000\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6622 - binary_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.6132\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6507 - binary_accuracy: 0.6044\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6545 - binary_accuracy: 0.5934\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6469 - binary_accuracy: 0.6154\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6544 - binary_accuracy: 0.5956\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6498 - binary_accuracy: 0.5934\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6575 - binary_accuracy: 0.6000\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6540 - binary_accuracy: 0.6110\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - binary_accuracy: 0.5978\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.6176\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - binary_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6432 - binary_accuracy: 0.6198\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - binary_accuracy: 0.6110\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - binary_accuracy: 0.6044\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6511 - binary_accuracy: 0.6022\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6477 - binary_accuracy: 0.6176\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - binary_accuracy: 0.6110\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6427 - binary_accuracy: 0.6176\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6420 - binary_accuracy: 0.6110\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6044\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6468 - binary_accuracy: 0.6088\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6370 - binary_accuracy: 0.6264\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6451 - binary_accuracy: 0.6132\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6440 - binary_accuracy: 0.5956\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6442 - binary_accuracy: 0.6132\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.6132\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - binary_accuracy: 0.5978\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6466 - binary_accuracy: 0.6022\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6370 - binary_accuracy: 0.6044\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6349 - binary_accuracy: 0.6110\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6491 - binary_accuracy: 0.5824\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6467 - binary_accuracy: 0.6044\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6373 - binary_accuracy: 0.6352\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6410 - binary_accuracy: 0.6220\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - binary_accuracy: 0.5846\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6391 - binary_accuracy: 0.6176\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6445 - binary_accuracy: 0.6176\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6463 - binary_accuracy: 0.6044\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6409 - binary_accuracy: 0.6154\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6444 - binary_accuracy: 0.6044\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - binary_accuracy: 0.6044\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6513 - binary_accuracy: 0.6088\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.6132\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - binary_accuracy: 0.6088\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6515 - binary_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.6198\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6520 - binary_accuracy: 0.6044\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6509 - binary_accuracy: 0.6110\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6400 - binary_accuracy: 0.6176\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.6022\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6408 - binary_accuracy: 0.6198\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.5978\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6448 - binary_accuracy: 0.6286\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - binary_accuracy: 0.6198\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - binary_accuracy: 0.6242\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6566 - binary_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6423 - binary_accuracy: 0.6176\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6493 - binary_accuracy: 0.6066\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6385 - binary_accuracy: 0.6220\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6411 - binary_accuracy: 0.6044\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6361 - binary_accuracy: 0.6264\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6557 - binary_accuracy: 0.6154\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6385 - binary_accuracy: 0.6088\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6396 - binary_accuracy: 0.6242\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.6110\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6345 - binary_accuracy: 0.6154\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6220\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6424 - binary_accuracy: 0.5978\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.5956\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6264\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - binary_accuracy: 0.6176\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6412 - binary_accuracy: 0.6088\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6418 - binary_accuracy: 0.6044\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.6066\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - binary_accuracy: 0.6132\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - binary_accuracy: 0.6154\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - binary_accuracy: 0.6154\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6417 - binary_accuracy: 0.6066\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6467 - binary_accuracy: 0.6066\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6359 - binary_accuracy: 0.6264\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6446 - binary_accuracy: 0.5978\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6132\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6911 - binary_accuracy: 0.5231\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6873 - binary_accuracy: 0.5560\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6709 - binary_accuracy: 0.5934\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6786 - binary_accuracy: 0.5824\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6776 - binary_accuracy: 0.5934\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6688 - binary_accuracy: 0.5978\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6725 - binary_accuracy: 0.5780\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6678 - binary_accuracy: 0.5780\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6638 - binary_accuracy: 0.5912\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6629 - binary_accuracy: 0.5802\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6603 - binary_accuracy: 0.5758\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6527 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6582 - binary_accuracy: 0.5824\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6575 - binary_accuracy: 0.5516\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6581 - binary_accuracy: 0.5736\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6601 - binary_accuracy: 0.5692\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6687 - binary_accuracy: 0.5604\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6548 - binary_accuracy: 0.5648\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6607 - binary_accuracy: 0.5495\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - binary_accuracy: 0.5780\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6601 - binary_accuracy: 0.5692\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.6022\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.5736\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - binary_accuracy: 0.5912\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6530 - binary_accuracy: 0.5780\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6618 - binary_accuracy: 0.5802\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - binary_accuracy: 0.5868\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.5670\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6550 - binary_accuracy: 0.5890\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6561 - binary_accuracy: 0.5626\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6551 - binary_accuracy: 0.5692\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6022\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - binary_accuracy: 0.6000\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - binary_accuracy: 0.5868\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6506 - binary_accuracy: 0.5934\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6468 - binary_accuracy: 0.5802\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6525 - binary_accuracy: 0.5736\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6483 - binary_accuracy: 0.5758\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6499 - binary_accuracy: 0.5956\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6510 - binary_accuracy: 0.5780\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6447 - binary_accuracy: 0.6022\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6455 - binary_accuracy: 0.5934\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - binary_accuracy: 0.5758\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - binary_accuracy: 0.5890\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - binary_accuracy: 0.5956\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6570 - binary_accuracy: 0.5714\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6412 - binary_accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6336 - binary_accuracy: 0.5758\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6489 - binary_accuracy: 0.5626\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.6044\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6474 - binary_accuracy: 0.5780\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - binary_accuracy: 0.5758\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.5846\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6522 - binary_accuracy: 0.5407\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6510 - binary_accuracy: 0.5516\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6515 - binary_accuracy: 0.5780\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6402 - binary_accuracy: 0.5934\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.5912\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6465 - binary_accuracy: 0.5626\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - binary_accuracy: 0.5495\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.5780\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.5648\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6494 - binary_accuracy: 0.5736\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6566 - binary_accuracy: 0.5868\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6605 - binary_accuracy: 0.5868\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6400 - binary_accuracy: 0.5956\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6533 - binary_accuracy: 0.5780\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - binary_accuracy: 0.5868\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6534 - binary_accuracy: 0.5978\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6446 - binary_accuracy: 0.5626\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.6176\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6426 - binary_accuracy: 0.5780\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6484 - binary_accuracy: 0.5758\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6597 - binary_accuracy: 0.5780\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6495 - binary_accuracy: 0.5824\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6447 - binary_accuracy: 0.5604\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6435 - binary_accuracy: 0.5604\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6358 - binary_accuracy: 0.5868\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6356 - binary_accuracy: 0.5934\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6365 - binary_accuracy: 0.6044\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6572 - binary_accuracy: 0.5231\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6558 - binary_accuracy: 0.5385\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6498 - binary_accuracy: 0.5714\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6478 - binary_accuracy: 0.5626\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - binary_accuracy: 0.5868\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.5692\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.5670\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.5604\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6475 - binary_accuracy: 0.5824\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6363 - binary_accuracy: 0.6132\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6355 - binary_accuracy: 0.5956\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6329 - binary_accuracy: 0.6132\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.5758\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6332 - binary_accuracy: 0.5824\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6487 - binary_accuracy: 0.5473\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6415 - binary_accuracy: 0.5890\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.5714\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6434 - binary_accuracy: 0.5890\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6454 - binary_accuracy: 0.5780\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6442 - binary_accuracy: 0.5868\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.7037 - binary_accuracy: 0.4627\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6899 - binary_accuracy: 0.5373\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6870 - binary_accuracy: 0.5570\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6787 - binary_accuracy: 0.5987\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6799 - binary_accuracy: 0.5746\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6782 - binary_accuracy: 0.5702\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6731 - binary_accuracy: 0.5965\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6723 - binary_accuracy: 0.5987\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6683 - binary_accuracy: 0.5965\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6664 - binary_accuracy: 0.5943\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6688 - binary_accuracy: 0.5921\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6680 - binary_accuracy: 0.5768\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6699 - binary_accuracy: 0.5855\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6716 - binary_accuracy: 0.5943\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6597 - binary_accuracy: 0.5833\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6623 - binary_accuracy: 0.5987\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6604 - binary_accuracy: 0.5899\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6560 - binary_accuracy: 0.5811\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6588 - binary_accuracy: 0.5877\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6610 - binary_accuracy: 0.5768\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6547 - binary_accuracy: 0.5702\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6606 - binary_accuracy: 0.5899\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6622 - binary_accuracy: 0.5636\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6658 - binary_accuracy: 0.5636\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6620 - binary_accuracy: 0.5570\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6621 - binary_accuracy: 0.5702\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6623 - binary_accuracy: 0.5592\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6591 - binary_accuracy: 0.5943\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.5789\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.5482\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6600 - binary_accuracy: 0.5768\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6644 - binary_accuracy: 0.5570\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6677 - binary_accuracy: 0.5526\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6545 - binary_accuracy: 0.5855\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6485 - binary_accuracy: 0.5899\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.5811\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6549 - binary_accuracy: 0.5965\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6550 - binary_accuracy: 0.5855\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6584 - binary_accuracy: 0.5636\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6567 - binary_accuracy: 0.5833\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_accuracy: 0.5636\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6528 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6577 - binary_accuracy: 0.5987\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6605 - binary_accuracy: 0.5702\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6614 - binary_accuracy: 0.5746\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6586 - binary_accuracy: 0.5592\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6590 - binary_accuracy: 0.5724\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6595 - binary_accuracy: 0.5833\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6601 - binary_accuracy: 0.5789\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6566 - binary_accuracy: 0.5877\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6623 - binary_accuracy: 0.5614\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.5811\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.6009\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6486 - binary_accuracy: 0.6053\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_accuracy: 0.5855\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6496 - binary_accuracy: 0.5943\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6572 - binary_accuracy: 0.5855\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6654 - binary_accuracy: 0.5592\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6521 - binary_accuracy: 0.5724\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6571 - binary_accuracy: 0.5768\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6623 - binary_accuracy: 0.5789\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6672 - binary_accuracy: 0.5592\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6570 - binary_accuracy: 0.5746\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6583 - binary_accuracy: 0.5987\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.5943\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6617 - binary_accuracy: 0.5680\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6598 - binary_accuracy: 0.5702\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6506 - binary_accuracy: 0.6009\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6545 - binary_accuracy: 0.5877\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6557 - binary_accuracy: 0.5592\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6571 - binary_accuracy: 0.5833\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6575 - binary_accuracy: 0.5285\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5526\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6561 - binary_accuracy: 0.5702\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - binary_accuracy: 0.5921\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.5768\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6599 - binary_accuracy: 0.5833\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6501 - binary_accuracy: 0.5987\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6476 - binary_accuracy: 0.6053\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6671 - binary_accuracy: 0.5768\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6600 - binary_accuracy: 0.5877\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6608 - binary_accuracy: 0.5855\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6582 - binary_accuracy: 0.5768\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6483 - binary_accuracy: 0.5987\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6556 - binary_accuracy: 0.5811\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6504 - binary_accuracy: 0.5833\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6536 - binary_accuracy: 0.5724\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6572 - binary_accuracy: 0.5855\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6547 - binary_accuracy: 0.5855\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6559 - binary_accuracy: 0.5811\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.5636\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6565 - binary_accuracy: 0.5987\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6502 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6507 - binary_accuracy: 0.5658\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6486 - binary_accuracy: 0.5702\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6485 - binary_accuracy: 0.5899\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6524 - binary_accuracy: 0.6031\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6543 - binary_accuracy: 0.5855\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6607 - binary_accuracy: 0.5439\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6628 - binary_accuracy: 0.5417\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.7659 - binary_accuracy: 0.6308\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7097 - binary_accuracy: 0.6769\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6826 - binary_accuracy: 0.6791\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6696 - binary_accuracy: 0.6813\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6581 - binary_accuracy: 0.6813\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6533 - binary_accuracy: 0.6835\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6500 - binary_accuracy: 0.6835\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6432 - binary_accuracy: 0.6835\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6422 - binary_accuracy: 0.6835\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6425 - binary_accuracy: 0.6835\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6404 - binary_accuracy: 0.6835\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6395 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6394 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6372 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6835\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6362 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6365 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6343 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6346 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6354 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6342 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6342 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6342 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6342 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6342 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6343 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6341 - binary_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6330 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6333 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6334 - binary_accuracy: 0.6835\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6329 - binary_accuracy: 0.6835\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6332 - binary_accuracy: 0.6835\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6322 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6314 - binary_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6835\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6300 - binary_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6257 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6129 - binary_accuracy: 0.7055\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.7275\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5983 - binary_accuracy: 0.7363\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5846 - binary_accuracy: 0.7516\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6769\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6427 - binary_accuracy: 0.6813\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6349 - binary_accuracy: 0.6857\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6343 - binary_accuracy: 0.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8520 - binary_accuracy: 0.5538\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8275 - binary_accuracy: 0.6440\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8038 - binary_accuracy: 0.6462\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7772 - binary_accuracy: 0.6418\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7615 - binary_accuracy: 0.6418\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7495 - binary_accuracy: 0.6418\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7388 - binary_accuracy: 0.6418\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7313 - binary_accuracy: 0.6418\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7278 - binary_accuracy: 0.6418\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7192 - binary_accuracy: 0.6418\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7154 - binary_accuracy: 0.6418\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7096 - binary_accuracy: 0.6462\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7097 - binary_accuracy: 0.6549\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7027 - binary_accuracy: 0.6747\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6827 - binary_accuracy: 0.7341\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6732 - binary_accuracy: 0.7516\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6565 - binary_accuracy: 0.7582\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6474 - binary_accuracy: 0.7846\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6253 - binary_accuracy: 0.8044\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6510 - binary_accuracy: 0.7648\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6249 - binary_accuracy: 0.7736\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6647 - binary_accuracy: 0.7209\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6585 - binary_accuracy: 0.7363\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.7824\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.7912\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6040 - binary_accuracy: 0.7956\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5706 - binary_accuracy: 0.8308\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.7802\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7246 - binary_accuracy: 0.6330\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7192 - binary_accuracy: 0.6418\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6967 - binary_accuracy: 0.6813\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6987 - binary_accuracy: 0.6681\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6857 - binary_accuracy: 0.6857\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7000 - binary_accuracy: 0.6659\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6913 - binary_accuracy: 0.7011\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7234 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6922 - binary_accuracy: 0.6703\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7008 - binary_accuracy: 0.6659\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7315 - binary_accuracy: 0.6330\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7653 - binary_accuracy: 0.6110\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7439 - binary_accuracy: 0.6110\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7007 - binary_accuracy: 0.6571\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6785 - binary_accuracy: 0.6901\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6778 - binary_accuracy: 0.6923\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6961 - binary_accuracy: 0.6703\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6827 - binary_accuracy: 0.6923\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6813 - binary_accuracy: 0.6923\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6750 - binary_accuracy: 0.6945\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6967 - binary_accuracy: 0.6637\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6841 - binary_accuracy: 0.6769\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7157 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6853 - binary_accuracy: 0.6857\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6686 - binary_accuracy: 0.7011\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7081 - binary_accuracy: 0.6527\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6933 - binary_accuracy: 0.6747\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7143 - binary_accuracy: 0.6396\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7019 - binary_accuracy: 0.6593\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7031 - binary_accuracy: 0.6527\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7089 - binary_accuracy: 0.6484\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6723 - binary_accuracy: 0.6945\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6675 - binary_accuracy: 0.6989\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6722 - binary_accuracy: 0.6923\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6741 - binary_accuracy: 0.6879\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6916 - binary_accuracy: 0.6769\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6505 - binary_accuracy: 0.7275\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6543 - binary_accuracy: 0.7143\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6693 - binary_accuracy: 0.6945\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6773 - binary_accuracy: 0.6945\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6402 - binary_accuracy: 0.7297\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6456 - binary_accuracy: 0.7341\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6419 - binary_accuracy: 0.7231\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.7121\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6367 - binary_accuracy: 0.7385\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6801 - binary_accuracy: 0.6791\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6835 - binary_accuracy: 0.6857\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7028 - binary_accuracy: 0.6527\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7130 - binary_accuracy: 0.6505\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7007 - binary_accuracy: 0.6637\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6872 - binary_accuracy: 0.6769\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.7385\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6227 - binary_accuracy: 0.7473\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - binary_accuracy: 0.7297\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6474 - binary_accuracy: 0.7275\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.7253\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6495 - binary_accuracy: 0.7253\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6414 - binary_accuracy: 0.7275\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6597 - binary_accuracy: 0.7143\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6760 - binary_accuracy: 0.6879\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6878 - binary_accuracy: 0.6769\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6914 - binary_accuracy: 0.6747\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6783 - binary_accuracy: 0.6857\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7005 - binary_accuracy: 0.6703\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6962 - binary_accuracy: 0.6791\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7057 - binary_accuracy: 0.6549\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6933 - binary_accuracy: 0.6725\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - binary_accuracy: 0.6681\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6808 - binary_accuracy: 0.6923\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6670 - binary_accuracy: 0.6923\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7119 - binary_accuracy: 0.6549\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.8827 - binary_accuracy: 0.4791\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8520 - binary_accuracy: 0.5956\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8306 - binary_accuracy: 0.6286\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8247 - binary_accuracy: 0.6110\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8151 - binary_accuracy: 0.6176\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7994 - binary_accuracy: 0.6264\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7957 - binary_accuracy: 0.6198\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7922 - binary_accuracy: 0.6198\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7777 - binary_accuracy: 0.6242\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7763 - binary_accuracy: 0.6198\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7715 - binary_accuracy: 0.6220\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7621 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7669 - binary_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7679 - binary_accuracy: 0.6242\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7696 - binary_accuracy: 0.6264\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7544 - binary_accuracy: 0.6220\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7564 - binary_accuracy: 0.6242\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7558 - binary_accuracy: 0.6286\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7611 - binary_accuracy: 0.6242\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7558 - binary_accuracy: 0.6308\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7498 - binary_accuracy: 0.6440\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7318 - binary_accuracy: 0.6571\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7479 - binary_accuracy: 0.6484\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7711 - binary_accuracy: 0.6286\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7605 - binary_accuracy: 0.6220\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7582 - binary_accuracy: 0.6198\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7512 - binary_accuracy: 0.6264\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7554 - binary_accuracy: 0.6264\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7546 - binary_accuracy: 0.6242\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7564 - binary_accuracy: 0.6330\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7526 - binary_accuracy: 0.6374\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - binary_accuracy: 0.6242\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7571 - binary_accuracy: 0.6198\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - binary_accuracy: 0.6198\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7519 - binary_accuracy: 0.6286\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7562 - binary_accuracy: 0.6220\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7603 - binary_accuracy: 0.6220\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7531 - binary_accuracy: 0.6330\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7469 - binary_accuracy: 0.6440\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7513 - binary_accuracy: 0.6286\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7731 - binary_accuracy: 0.5824\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7562 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7432 - binary_accuracy: 0.6220\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7521 - binary_accuracy: 0.6220\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7535 - binary_accuracy: 0.6330\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7423 - binary_accuracy: 0.6352\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7553 - binary_accuracy: 0.6264\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7331 - binary_accuracy: 0.6659\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7268 - binary_accuracy: 0.6725\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7422 - binary_accuracy: 0.6418\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7344 - binary_accuracy: 0.6593\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7292 - binary_accuracy: 0.6703\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7447 - binary_accuracy: 0.6374\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7264 - binary_accuracy: 0.6571\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7756 - binary_accuracy: 0.6088\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7885 - binary_accuracy: 0.5934\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7654 - binary_accuracy: 0.6110\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7344 - binary_accuracy: 0.6593\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7436 - binary_accuracy: 0.6220\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7323 - binary_accuracy: 0.6549\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7202 - binary_accuracy: 0.6659\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6963 - binary_accuracy: 0.6923\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7434 - binary_accuracy: 0.6330\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7124 - binary_accuracy: 0.6813\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7113 - binary_accuracy: 0.6967\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7536 - binary_accuracy: 0.6308\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7529 - binary_accuracy: 0.6220\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7413 - binary_accuracy: 0.6484\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - binary_accuracy: 0.6330\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7366 - binary_accuracy: 0.6505\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - binary_accuracy: 0.6374\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - binary_accuracy: 0.6330\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7332 - binary_accuracy: 0.6725\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7315 - binary_accuracy: 0.6593\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7300 - binary_accuracy: 0.6462\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7350 - binary_accuracy: 0.6396\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7260 - binary_accuracy: 0.6571\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7301 - binary_accuracy: 0.6659\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7217 - binary_accuracy: 0.6747\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7264 - binary_accuracy: 0.6593\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7674 - binary_accuracy: 0.6088\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8124 - binary_accuracy: 0.5516\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7907 - binary_accuracy: 0.5846\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7428 - binary_accuracy: 0.6286\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7359 - binary_accuracy: 0.6505\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7304 - binary_accuracy: 0.6527\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7204 - binary_accuracy: 0.6681\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - binary_accuracy: 0.6571\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7146 - binary_accuracy: 0.6659\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7255 - binary_accuracy: 0.6527\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7009 - binary_accuracy: 0.6901\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7122 - binary_accuracy: 0.6659\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7202 - binary_accuracy: 0.6637\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7052 - binary_accuracy: 0.6857\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7778 - binary_accuracy: 0.6044\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7673 - binary_accuracy: 0.6110\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7137 - binary_accuracy: 0.6747\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7122 - binary_accuracy: 0.6725\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7518 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8975 - binary_accuracy: 0.5209\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8739 - binary_accuracy: 0.5912\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8558 - binary_accuracy: 0.5934\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8443 - binary_accuracy: 0.5934\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8353 - binary_accuracy: 0.5978\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8311 - binary_accuracy: 0.5978\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8219 - binary_accuracy: 0.5978\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8222 - binary_accuracy: 0.5956\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8151 - binary_accuracy: 0.5978\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8139 - binary_accuracy: 0.5978\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8124 - binary_accuracy: 0.5978\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8126 - binary_accuracy: 0.5956\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8127 - binary_accuracy: 0.5978\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8087 - binary_accuracy: 0.5978\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8091 - binary_accuracy: 0.5978\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8094 - binary_accuracy: 0.5978\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8086 - binary_accuracy: 0.5978\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8094 - binary_accuracy: 0.5978\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8086 - binary_accuracy: 0.5978\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8080 - binary_accuracy: 0.5978\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8093 - binary_accuracy: 0.5978\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8072 - binary_accuracy: 0.5978\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8070 - binary_accuracy: 0.5978\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8072 - binary_accuracy: 0.5978\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8066 - binary_accuracy: 0.5978\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8045 - binary_accuracy: 0.6000\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8072 - binary_accuracy: 0.5978\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8046 - binary_accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8054 - binary_accuracy: 0.5978\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8039 - binary_accuracy: 0.5978\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8039 - binary_accuracy: 0.5978\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8041 - binary_accuracy: 0.5978\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8076 - binary_accuracy: 0.5978\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8064 - binary_accuracy: 0.5978\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8064 - binary_accuracy: 0.5978\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8070 - binary_accuracy: 0.5978\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8066 - binary_accuracy: 0.5978\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8060 - binary_accuracy: 0.5978\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8056 - binary_accuracy: 0.5978\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8066 - binary_accuracy: 0.5978\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8058 - binary_accuracy: 0.5978\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8055 - binary_accuracy: 0.5978\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8056 - binary_accuracy: 0.5978\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8054 - binary_accuracy: 0.5978\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8055 - binary_accuracy: 0.5978\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8052 - binary_accuracy: 0.5978\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8052 - binary_accuracy: 0.5978\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8059 - binary_accuracy: 0.5978\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8045 - binary_accuracy: 0.5978\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8052 - binary_accuracy: 0.5978\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8055 - binary_accuracy: 0.5978\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8045 - binary_accuracy: 0.5978\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8047 - binary_accuracy: 0.5978\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8052 - binary_accuracy: 0.5978\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8055 - binary_accuracy: 0.5978\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8047 - binary_accuracy: 0.5978\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8047 - binary_accuracy: 0.5978\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8047 - binary_accuracy: 0.5978\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8051 - binary_accuracy: 0.5978\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8045 - binary_accuracy: 0.5978\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8045 - binary_accuracy: 0.5978\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8052 - binary_accuracy: 0.5978\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8048 - binary_accuracy: 0.5978\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8047 - binary_accuracy: 0.5978\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8049 - binary_accuracy: 0.5978\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8046 - binary_accuracy: 0.5978\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8920 - binary_accuracy: 0.5855\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8605 - binary_accuracy: 0.5811\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8333 - binary_accuracy: 0.6184\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8214 - binary_accuracy: 0.6338\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8020 - binary_accuracy: 0.6820\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7729 - binary_accuracy: 0.7368\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7618 - binary_accuracy: 0.7281\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7322 - binary_accuracy: 0.7632\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7242 - binary_accuracy: 0.7566\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7272 - binary_accuracy: 0.7632\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7343 - binary_accuracy: 0.7544\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7041 - binary_accuracy: 0.7588\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7014 - binary_accuracy: 0.7522\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6875 - binary_accuracy: 0.7697\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6691 - binary_accuracy: 0.7697\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6414 - binary_accuracy: 0.8180\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6336 - binary_accuracy: 0.8136\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6502 - binary_accuracy: 0.7851\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6192 - binary_accuracy: 0.8289\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6396 - binary_accuracy: 0.8070\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6488 - binary_accuracy: 0.7873\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6339 - binary_accuracy: 0.8070\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.8070\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5962 - binary_accuracy: 0.8421\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5775 - binary_accuracy: 0.8575\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5793 - binary_accuracy: 0.8662\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5676 - binary_accuracy: 0.8772\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5660 - binary_accuracy: 0.8750\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5878 - binary_accuracy: 0.8443\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5824 - binary_accuracy: 0.8487\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5626 - binary_accuracy: 0.8618\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5674 - binary_accuracy: 0.8531\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5738 - binary_accuracy: 0.8465\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5522 - binary_accuracy: 0.8794\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5670 - binary_accuracy: 0.8553\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5547 - binary_accuracy: 0.8662\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5626 - binary_accuracy: 0.8596\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_accuracy: 0.7829\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7379 - binary_accuracy: 0.6732\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6362 - binary_accuracy: 0.7829\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5943 - binary_accuracy: 0.8268\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5700 - binary_accuracy: 0.8531\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5829 - binary_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5502 - binary_accuracy: 0.8706\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5557 - binary_accuracy: 0.8684\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5650 - binary_accuracy: 0.8596\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5470 - binary_accuracy: 0.8772\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5910 - binary_accuracy: 0.8289\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5820 - binary_accuracy: 0.8399\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5799 - binary_accuracy: 0.8487\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5656 - binary_accuracy: 0.8531\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5525 - binary_accuracy: 0.8750\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5500 - binary_accuracy: 0.8662\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5649 - binary_accuracy: 0.8618\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5726 - binary_accuracy: 0.8487\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5520 - binary_accuracy: 0.8640\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5709 - binary_accuracy: 0.8421\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5545 - binary_accuracy: 0.8750\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7989 - binary_accuracy: 0.6053\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7936 - binary_accuracy: 0.6184\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7454 - binary_accuracy: 0.6601\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7294 - binary_accuracy: 0.6908\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7435 - binary_accuracy: 0.6689\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - binary_accuracy: 0.6798\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7355 - binary_accuracy: 0.6776\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7411 - binary_accuracy: 0.6842\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7165 - binary_accuracy: 0.7039\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7207 - binary_accuracy: 0.6930\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7047 - binary_accuracy: 0.7193\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7224 - binary_accuracy: 0.6952\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7410 - binary_accuracy: 0.6689\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6857 - binary_accuracy: 0.7478\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7329 - binary_accuracy: 0.6798\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7289 - binary_accuracy: 0.6864\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7328 - binary_accuracy: 0.6952\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7442 - binary_accuracy: 0.6732\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - binary_accuracy: 0.6776\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - binary_accuracy: 0.6776\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7474 - binary_accuracy: 0.6667\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7120 - binary_accuracy: 0.7061\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7045 - binary_accuracy: 0.7149\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7316 - binary_accuracy: 0.6864\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7574 - binary_accuracy: 0.6579\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - binary_accuracy: 0.6316\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7494 - binary_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7155 - binary_accuracy: 0.7018\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7518 - binary_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7430 - binary_accuracy: 0.6689\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7251 - binary_accuracy: 0.6908\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7339 - binary_accuracy: 0.6864\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7437 - binary_accuracy: 0.6491\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7329 - binary_accuracy: 0.6776\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7337 - binary_accuracy: 0.6864\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6955 - binary_accuracy: 0.7259\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6968 - binary_accuracy: 0.7105\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7113 - binary_accuracy: 0.7018\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7195 - binary_accuracy: 0.6930\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7094 - binary_accuracy: 0.7018\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7172 - binary_accuracy: 0.6842\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7297 - binary_accuracy: 0.6820\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.8109 - binary_accuracy: 0.5495\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7905 - binary_accuracy: 0.6571\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7709 - binary_accuracy: 0.6725\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7580 - binary_accuracy: 0.6835\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - binary_accuracy: 0.6813\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7299 - binary_accuracy: 0.6769\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7215 - binary_accuracy: 0.6813\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7156 - binary_accuracy: 0.6813\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7110 - binary_accuracy: 0.6835\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7035 - binary_accuracy: 0.6835\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7006 - binary_accuracy: 0.6813\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6944 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6961 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6892 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6833 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6849 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6823 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6773 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6778 - binary_accuracy: 0.6813\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6742 - binary_accuracy: 0.6813\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6717 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6717 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6691 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6714 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6680 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6684 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6637 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6628 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6621 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6621 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6616 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6605 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6601 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6588 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6585 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6592 - binary_accuracy: 0.6835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6574 - binary_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6553 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6563 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6567 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6554 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6531 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6539 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6549 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6538 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6521 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6514 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6509 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6502 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6513 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6484 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6485 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6490 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6491 - binary_accuracy: 0.6835\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6478 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6489 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6490 - binary_accuracy: 0.6835\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6481 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6496 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6475 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6492 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6472 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_accuracy: 0.6835\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6467 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6457 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6456 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6482 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6453 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6445 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6437 - binary_accuracy: 0.6835\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6448 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - binary_accuracy: 0.6835\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6455 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - binary_accuracy: 0.6835\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6436 - binary_accuracy: 0.6835\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6448 - binary_accuracy: 0.6835\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6460 - binary_accuracy: 0.6835\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6450 - binary_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6449 - binary_accuracy: 0.6835\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6453 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6436 - binary_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6440 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6444 - binary_accuracy: 0.6835\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6439 - binary_accuracy: 0.6835\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6417 - binary_accuracy: 0.6835\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6439 - binary_accuracy: 0.6835\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.6835\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6430 - binary_accuracy: 0.6835\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.6835\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6434 - binary_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6428 - binary_accuracy: 0.6835\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6409 - binary_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6416 - binary_accuracy: 0.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6421 - binary_accuracy: 0.6835\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8198 - binary_accuracy: 0.6066\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8173 - binary_accuracy: 0.6066\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8046 - binary_accuracy: 0.6088\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7923 - binary_accuracy: 0.6198\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7819 - binary_accuracy: 0.6088\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7819 - binary_accuracy: 0.6154\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7809 - binary_accuracy: 0.6154\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7718 - binary_accuracy: 0.6330\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7747 - binary_accuracy: 0.6132\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7688 - binary_accuracy: 0.6264\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7625 - binary_accuracy: 0.6242\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7594 - binary_accuracy: 0.6264\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7570 - binary_accuracy: 0.6264\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7541 - binary_accuracy: 0.6352\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7544 - binary_accuracy: 0.6264\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7560 - binary_accuracy: 0.6264\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7533 - binary_accuracy: 0.6330\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7526 - binary_accuracy: 0.6352\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7501 - binary_accuracy: 0.6330\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - binary_accuracy: 0.6396\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7497 - binary_accuracy: 0.6352\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7460 - binary_accuracy: 0.6396\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7458 - binary_accuracy: 0.6352\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7418 - binary_accuracy: 0.6462\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7470 - binary_accuracy: 0.6396\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7386 - binary_accuracy: 0.6418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7396 - binary_accuracy: 0.6462\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7404 - binary_accuracy: 0.6440\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7391 - binary_accuracy: 0.6374\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7393 - binary_accuracy: 0.6374\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7385 - binary_accuracy: 0.6374\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7388 - binary_accuracy: 0.6418\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7385 - binary_accuracy: 0.6396\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7371 - binary_accuracy: 0.6396\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7372 - binary_accuracy: 0.6396\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7363 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - binary_accuracy: 0.6352\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - binary_accuracy: 0.6484\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7358 - binary_accuracy: 0.6440\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7326 - binary_accuracy: 0.6440\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7323 - binary_accuracy: 0.6440\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7354 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7305 - binary_accuracy: 0.6418\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7346 - binary_accuracy: 0.6418\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7329 - binary_accuracy: 0.6418\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7295 - binary_accuracy: 0.6418\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7330 - binary_accuracy: 0.6418\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7298 - binary_accuracy: 0.6418\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7295 - binary_accuracy: 0.6418\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7306 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7302 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7281 - binary_accuracy: 0.6418\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7286 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7303 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7296 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7287 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7285 - binary_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7289 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7268 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7303 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7258 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7262 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7272 - binary_accuracy: 0.6418\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7266 - binary_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7294 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7291 - binary_accuracy: 0.6418\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7272 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7279 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7274 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7263 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7264 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7264 - binary_accuracy: 0.6418\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7276 - binary_accuracy: 0.6418\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7222 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7268 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7243 - binary_accuracy: 0.6418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7238 - binary_accuracy: 0.6418\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7242 - binary_accuracy: 0.6418\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7269 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7244 - binary_accuracy: 0.6418\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7226 - binary_accuracy: 0.6418\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7250 - binary_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7267 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7238 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7268 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7240 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7251 - binary_accuracy: 0.6418\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7260 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7250 - binary_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7242 - binary_accuracy: 0.6418\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7224 - binary_accuracy: 0.6418\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7232 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7219 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7253 - binary_accuracy: 0.6418\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7226 - binary_accuracy: 0.6396\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7231 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 5ms/step - loss: 0.8751 - binary_accuracy: 0.5253\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8574 - binary_accuracy: 0.5780\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8499 - binary_accuracy: 0.6110\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8382 - binary_accuracy: 0.6044\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8311 - binary_accuracy: 0.6154\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.6220\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.6198\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8082 - binary_accuracy: 0.6220\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7972 - binary_accuracy: 0.6242\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7924 - binary_accuracy: 0.6220\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8076 - binary_accuracy: 0.6198\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8022 - binary_accuracy: 0.6220\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8014 - binary_accuracy: 0.6220\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7962 - binary_accuracy: 0.6198\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7943 - binary_accuracy: 0.6220\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7895 - binary_accuracy: 0.6220\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7897 - binary_accuracy: 0.6220\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7849 - binary_accuracy: 0.6220\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7892 - binary_accuracy: 0.6198\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7809 - binary_accuracy: 0.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7868 - binary_accuracy: 0.6220\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7806 - binary_accuracy: 0.6220\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7792 - binary_accuracy: 0.6220\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7798 - binary_accuracy: 0.6220\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7788 - binary_accuracy: 0.6220\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7768 - binary_accuracy: 0.6220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7752 - binary_accuracy: 0.6242\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7788 - binary_accuracy: 0.6220\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7730 - binary_accuracy: 0.6220\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7743 - binary_accuracy: 0.6220\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7744 - binary_accuracy: 0.6220\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7711 - binary_accuracy: 0.6220\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7733 - binary_accuracy: 0.6220\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7723 - binary_accuracy: 0.6220\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7712 - binary_accuracy: 0.6220\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7712 - binary_accuracy: 0.6220\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7717 - binary_accuracy: 0.6220\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7708 - binary_accuracy: 0.6220\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7712 - binary_accuracy: 0.6220\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7702 - binary_accuracy: 0.6220\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7721 - binary_accuracy: 0.6220\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7666 - binary_accuracy: 0.6220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - binary_accuracy: 0.6220\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7666 - binary_accuracy: 0.6220\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7696 - binary_accuracy: 0.6220\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7697 - binary_accuracy: 0.6220\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7673 - binary_accuracy: 0.6220\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7669 - binary_accuracy: 0.6220\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7681 - binary_accuracy: 0.6220\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7677 - binary_accuracy: 0.6220\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7702 - binary_accuracy: 0.6220\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7656 - binary_accuracy: 0.6220\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7675 - binary_accuracy: 0.6220\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7673 - binary_accuracy: 0.6220\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7651 - binary_accuracy: 0.6220\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7671 - binary_accuracy: 0.6220\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7681 - binary_accuracy: 0.6220\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7642 - binary_accuracy: 0.6220\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7675 - binary_accuracy: 0.6220\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7681 - binary_accuracy: 0.6220\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7654 - binary_accuracy: 0.6220\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7656 - binary_accuracy: 0.6220\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7642 - binary_accuracy: 0.6220\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7640 - binary_accuracy: 0.6220\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7649 - binary_accuracy: 0.6220\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7621 - binary_accuracy: 0.6220\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7651 - binary_accuracy: 0.6220\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - binary_accuracy: 0.6220\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7636 - binary_accuracy: 0.6220\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7627 - binary_accuracy: 0.6220\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7650 - binary_accuracy: 0.6220\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - binary_accuracy: 0.6220\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7615 - binary_accuracy: 0.6220\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7638 - binary_accuracy: 0.6220\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7615 - binary_accuracy: 0.6220\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7657 - binary_accuracy: 0.6220\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7643 - binary_accuracy: 0.6220\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7643 - binary_accuracy: 0.6220\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7604 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7650 - binary_accuracy: 0.6220\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7633 - binary_accuracy: 0.6220\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7606 - binary_accuracy: 0.6220\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7646 - binary_accuracy: 0.6220\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7630 - binary_accuracy: 0.6220\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7625 - binary_accuracy: 0.6220\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7613 - binary_accuracy: 0.6220\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7638 - binary_accuracy: 0.6220\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7614 - binary_accuracy: 0.6220\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7622 - binary_accuracy: 0.6220\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7635 - binary_accuracy: 0.6220\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7628 - binary_accuracy: 0.6220\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7621 - binary_accuracy: 0.6220\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7622 - binary_accuracy: 0.6220\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7624 - binary_accuracy: 0.6220\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7632 - binary_accuracy: 0.6220\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7632 - binary_accuracy: 0.6220\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7631 - binary_accuracy: 0.6220\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.9085 - binary_accuracy: 0.4659\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8949 - binary_accuracy: 0.5538\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8877 - binary_accuracy: 0.5692\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8889 - binary_accuracy: 0.5604\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8843 - binary_accuracy: 0.5714\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8871 - binary_accuracy: 0.5780\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8759 - binary_accuracy: 0.5758\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8792 - binary_accuracy: 0.5736\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8711 - binary_accuracy: 0.5846\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8721 - binary_accuracy: 0.5780\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8679 - binary_accuracy: 0.5846\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8673 - binary_accuracy: 0.5824\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8683 - binary_accuracy: 0.5868\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8637 - binary_accuracy: 0.5868\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8643 - binary_accuracy: 0.5824\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8603 - binary_accuracy: 0.5824\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8580 - binary_accuracy: 0.5934\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8577 - binary_accuracy: 0.5890\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8564 - binary_accuracy: 0.5890\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8526 - binary_accuracy: 0.5912\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8545 - binary_accuracy: 0.5934\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8481 - binary_accuracy: 0.5890\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8475 - binary_accuracy: 0.5868\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8419 - binary_accuracy: 0.5912\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8444 - binary_accuracy: 0.5912\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8441 - binary_accuracy: 0.5890\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8436 - binary_accuracy: 0.5846\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8443 - binary_accuracy: 0.5956\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8402 - binary_accuracy: 0.5934\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8372 - binary_accuracy: 0.5956\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8384 - binary_accuracy: 0.5934\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8352 - binary_accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8330 - binary_accuracy: 0.5978\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8362 - binary_accuracy: 0.5978\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8326 - binary_accuracy: 0.5978\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8349 - binary_accuracy: 0.5956\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8308 - binary_accuracy: 0.5978\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8297 - binary_accuracy: 0.5956\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8307 - binary_accuracy: 0.5956\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8326 - binary_accuracy: 0.5978\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8294 - binary_accuracy: 0.5956\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8287 - binary_accuracy: 0.5956\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8302 - binary_accuracy: 0.5934\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8264 - binary_accuracy: 0.5956\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8271 - binary_accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8295 - binary_accuracy: 0.5956\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8304 - binary_accuracy: 0.5978\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8281 - binary_accuracy: 0.6000\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8277 - binary_accuracy: 0.5934\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8256 - binary_accuracy: 0.5978\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8235 - binary_accuracy: 0.5978\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8262 - binary_accuracy: 0.5956\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8277 - binary_accuracy: 0.5978\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8259 - binary_accuracy: 0.5956\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8258 - binary_accuracy: 0.5956\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8245 - binary_accuracy: 0.5978\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8242 - binary_accuracy: 0.6000\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8219 - binary_accuracy: 0.6000\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5978\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8258 - binary_accuracy: 0.5934\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8207 - binary_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8236 - binary_accuracy: 0.5956\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8260 - binary_accuracy: 0.5956\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8223 - binary_accuracy: 0.5978\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8213 - binary_accuracy: 0.5978\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8217 - binary_accuracy: 0.5956\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8170 - binary_accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8167 - binary_accuracy: 0.5978\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8228 - binary_accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8161 - binary_accuracy: 0.5978\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8136 - binary_accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8184 - binary_accuracy: 0.5956\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8169 - binary_accuracy: 0.5978\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8174 - binary_accuracy: 0.6022\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8145 - binary_accuracy: 0.5978\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8165 - binary_accuracy: 0.6000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8158 - binary_accuracy: 0.5934\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8172 - binary_accuracy: 0.5934\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8167 - binary_accuracy: 0.5978\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8146 - binary_accuracy: 0.5978\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8181 - binary_accuracy: 0.5978\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8144 - binary_accuracy: 0.6000\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8172 - binary_accuracy: 0.5978\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8178 - binary_accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8168 - binary_accuracy: 0.6044\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8134 - binary_accuracy: 0.5978\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8148 - binary_accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8163 - binary_accuracy: 0.6022\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8135 - binary_accuracy: 0.5978\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8159 - binary_accuracy: 0.5956\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8165 - binary_accuracy: 0.5956\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8170 - binary_accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8181 - binary_accuracy: 0.5956\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8155 - binary_accuracy: 0.5956\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8193 - binary_accuracy: 0.5934\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8143 - binary_accuracy: 0.6066\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8160 - binary_accuracy: 0.5956\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8162 - binary_accuracy: 0.5956\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.9032 - binary_accuracy: 0.5263\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9000 - binary_accuracy: 0.5439\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8950 - binary_accuracy: 0.6031\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8920 - binary_accuracy: 0.5702\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8883 - binary_accuracy: 0.5987\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8874 - binary_accuracy: 0.5921\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8853 - binary_accuracy: 0.5811\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8771 - binary_accuracy: 0.6031\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8796 - binary_accuracy: 0.5943\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8744 - binary_accuracy: 0.5855\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8701 - binary_accuracy: 0.5899\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8719 - binary_accuracy: 0.5899\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8681 - binary_accuracy: 0.5943\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8685 - binary_accuracy: 0.5899\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8654 - binary_accuracy: 0.5921\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8593 - binary_accuracy: 0.5965\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8553 - binary_accuracy: 0.5943\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8615 - binary_accuracy: 0.5921\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8561 - binary_accuracy: 0.5921\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8471 - binary_accuracy: 0.5921\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8553 - binary_accuracy: 0.5921\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8486 - binary_accuracy: 0.5943\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8485 - binary_accuracy: 0.5921\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8456 - binary_accuracy: 0.5921\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8455 - binary_accuracy: 0.5921\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8459 - binary_accuracy: 0.5921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8454 - binary_accuracy: 0.5877\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8452 - binary_accuracy: 0.5943\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8477 - binary_accuracy: 0.5921\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8478 - binary_accuracy: 0.5921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8419 - binary_accuracy: 0.5943\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8357 - binary_accuracy: 0.5877\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8379 - binary_accuracy: 0.5899\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8312 - binary_accuracy: 0.5921\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8362 - binary_accuracy: 0.5877\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8372 - binary_accuracy: 0.5921\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8459 - binary_accuracy: 0.5921\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8413 - binary_accuracy: 0.5921\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8379 - binary_accuracy: 0.5899\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8378 - binary_accuracy: 0.5943\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8323 - binary_accuracy: 0.5921\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8364 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8388 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8373 - binary_accuracy: 0.5921\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8318 - binary_accuracy: 0.5943\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8354 - binary_accuracy: 0.5943\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8339 - binary_accuracy: 0.5921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8292 - binary_accuracy: 0.5921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8240 - binary_accuracy: 0.5921\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8296 - binary_accuracy: 0.5921\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8381 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8290 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8292 - binary_accuracy: 0.5921\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8266 - binary_accuracy: 0.5921\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8284 - binary_accuracy: 0.5921\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8243 - binary_accuracy: 0.5921\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8252 - binary_accuracy: 0.5943\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8229 - binary_accuracy: 0.5943\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8237 - binary_accuracy: 0.5921\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8205 - binary_accuracy: 0.5943\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8244 - binary_accuracy: 0.5943\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8229 - binary_accuracy: 0.5899\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8239 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8244 - binary_accuracy: 0.5921\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8298 - binary_accuracy: 0.5899\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8199 - binary_accuracy: 0.5943\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8185 - binary_accuracy: 0.5921\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8173 - binary_accuracy: 0.5899\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8296 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8268 - binary_accuracy: 0.5921\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8291 - binary_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8233 - binary_accuracy: 0.5943\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8241 - binary_accuracy: 0.5943\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8220 - binary_accuracy: 0.5921\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8273 - binary_accuracy: 0.5877\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8291 - binary_accuracy: 0.5987\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8298 - binary_accuracy: 0.5877\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8286 - binary_accuracy: 0.5921\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8284 - binary_accuracy: 0.5899\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8284 - binary_accuracy: 0.5943\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8269 - binary_accuracy: 0.5921\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8318 - binary_accuracy: 0.5921\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8250 - binary_accuracy: 0.5921\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8306 - binary_accuracy: 0.5921\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8288 - binary_accuracy: 0.5921\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8291 - binary_accuracy: 0.5921\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8247 - binary_accuracy: 0.5943\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8253 - binary_accuracy: 0.5899\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8227 - binary_accuracy: 0.5921\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8280 - binary_accuracy: 0.5921\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8307 - binary_accuracy: 0.5921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8261 - binary_accuracy: 0.5899\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8245 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8250 - binary_accuracy: 0.5943\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8272 - binary_accuracy: 0.5899\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8273 - binary_accuracy: 0.5921\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8283 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8296 - binary_accuracy: 0.5943\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8206 - binary_accuracy: 0.5921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8321 - binary_accuracy: 0.5921\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.7981 - binary_accuracy: 0.6527\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7757 - binary_accuracy: 0.6857\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7487 - binary_accuracy: 0.6857\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7277 - binary_accuracy: 0.6835\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7150 - binary_accuracy: 0.6835\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7002 - binary_accuracy: 0.6857\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6922 - binary_accuracy: 0.6835\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6818 - binary_accuracy: 0.6835\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6742 - binary_accuracy: 0.6857\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6701 - binary_accuracy: 0.6835\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6642 - binary_accuracy: 0.6857\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6626 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6578 - binary_accuracy: 0.6835\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6579 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6517 - binary_accuracy: 0.6835\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6496 - binary_accuracy: 0.6835\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6472 - binary_accuracy: 0.6835\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6477 - binary_accuracy: 0.6835\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6488 - binary_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6442 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6414 - binary_accuracy: 0.6835\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6423 - binary_accuracy: 0.6835\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6412 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6438 - binary_accuracy: 0.6835\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6425 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6414 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6412 - binary_accuracy: 0.6835\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6395 - binary_accuracy: 0.6835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6835\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6395 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6401 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6401 - binary_accuracy: 0.6835\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6392 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6377 - binary_accuracy: 0.6857\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.6835\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6406 - binary_accuracy: 0.6835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6378 - binary_accuracy: 0.6835\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6385 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - binary_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6375 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6392 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6835\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6371 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6380 - binary_accuracy: 0.6835\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6857\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6360 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6369 - binary_accuracy: 0.6835\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6335 - binary_accuracy: 0.6879\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6351 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6357 - binary_accuracy: 0.6835\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6857\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6835\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6359 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6835\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6879\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6346 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6835\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6835\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6348 - binary_accuracy: 0.6835\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6368 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6359 - binary_accuracy: 0.6835\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6346 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6341 - binary_accuracy: 0.6835\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6335 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6340 - binary_accuracy: 0.6813\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6321 - binary_accuracy: 0.6857\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6330 - binary_accuracy: 0.6857\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6326 - binary_accuracy: 0.6857\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6857\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6330 - binary_accuracy: 0.6879\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6835\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.6835\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6308 - binary_accuracy: 0.6901\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6341 - binary_accuracy: 0.6835\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6835\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6324 - binary_accuracy: 0.6879\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6857\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6313 - binary_accuracy: 0.6879\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.6879\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6879\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6323 - binary_accuracy: 0.6857\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6313 - binary_accuracy: 0.6879\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6341 - binary_accuracy: 0.6813\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8462 - binary_accuracy: 0.6088\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8266 - binary_accuracy: 0.6659\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8148 - binary_accuracy: 0.6330\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7939 - binary_accuracy: 0.6418\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7826 - binary_accuracy: 0.6330\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7778 - binary_accuracy: 0.6418\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7626 - binary_accuracy: 0.6462\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7575 - binary_accuracy: 0.6396\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7526 - binary_accuracy: 0.6418\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7552 - binary_accuracy: 0.6440\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7410 - binary_accuracy: 0.6418\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7431 - binary_accuracy: 0.6396\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7395 - binary_accuracy: 0.6440\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7378 - binary_accuracy: 0.6396\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7363 - binary_accuracy: 0.6418\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7353 - binary_accuracy: 0.6396\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7291 - binary_accuracy: 0.6418\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7341 - binary_accuracy: 0.6418\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7341 - binary_accuracy: 0.6396\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7306 - binary_accuracy: 0.6418\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7317 - binary_accuracy: 0.6418\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7359 - binary_accuracy: 0.6418\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7313 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7311 - binary_accuracy: 0.6418\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7280 - binary_accuracy: 0.6418\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7243 - binary_accuracy: 0.6396\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7275 - binary_accuracy: 0.6396\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7220 - binary_accuracy: 0.6418\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7265 - binary_accuracy: 0.6418\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7229 - binary_accuracy: 0.6418\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7233 - binary_accuracy: 0.6418\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7231 - binary_accuracy: 0.6418\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7245 - binary_accuracy: 0.6418\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7220 - binary_accuracy: 0.6418\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7210 - binary_accuracy: 0.6418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7200 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7239 - binary_accuracy: 0.6396\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7212 - binary_accuracy: 0.6418\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7218 - binary_accuracy: 0.6418\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7244 - binary_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7194 - binary_accuracy: 0.6418\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7199 - binary_accuracy: 0.6418\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7201 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7218 - binary_accuracy: 0.6418\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7200 - binary_accuracy: 0.6418\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7200 - binary_accuracy: 0.6418\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7194 - binary_accuracy: 0.6418\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7189 - binary_accuracy: 0.6418\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7212 - binary_accuracy: 0.6418\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7197 - binary_accuracy: 0.6418\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7189 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7201 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7198 - binary_accuracy: 0.6418\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7201 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7199 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7188 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7188 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7199 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7190 - binary_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7195 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7194 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7185 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7187 - binary_accuracy: 0.6418\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7190 - binary_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7174 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7190 - binary_accuracy: 0.6418\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7187 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7189 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7165 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7184 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7173 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7173 - binary_accuracy: 0.6418\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7185 - binary_accuracy: 0.6418\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7195 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7187 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7177 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7181 - binary_accuracy: 0.6418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7173 - binary_accuracy: 0.6440\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7173 - binary_accuracy: 0.6418\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7177 - binary_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7171 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7192 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7176 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7182 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7173 - binary_accuracy: 0.6418\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7175 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7172 - binary_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7172 - binary_accuracy: 0.6418\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7166 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7178 - binary_accuracy: 0.6418\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7173 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7177 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7180 - binary_accuracy: 0.6418\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7179 - binary_accuracy: 0.6418\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7176 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.8691 - binary_accuracy: 0.5736\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8594 - binary_accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8523 - binary_accuracy: 0.6220\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8427 - binary_accuracy: 0.6286\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8311 - binary_accuracy: 0.6725\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8235 - binary_accuracy: 0.6505\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8304 - binary_accuracy: 0.6198\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8260 - binary_accuracy: 0.6396\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8001 - binary_accuracy: 0.6703\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7870 - binary_accuracy: 0.6659\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7805 - binary_accuracy: 0.6637\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7796 - binary_accuracy: 0.6703\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7655 - binary_accuracy: 0.6989\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7548 - binary_accuracy: 0.6593\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7653 - binary_accuracy: 0.6418\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7643 - binary_accuracy: 0.6330\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7588 - binary_accuracy: 0.6440\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7732 - binary_accuracy: 0.6681\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7620 - binary_accuracy: 0.6462\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7394 - binary_accuracy: 0.6945\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7504 - binary_accuracy: 0.6747\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7386 - binary_accuracy: 0.6791\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7324 - binary_accuracy: 0.6791\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7164 - binary_accuracy: 0.6967\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7177 - binary_accuracy: 0.7033\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7110 - binary_accuracy: 0.6989\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7057 - binary_accuracy: 0.6967\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6890 - binary_accuracy: 0.7253\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6995 - binary_accuracy: 0.7055\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6981 - binary_accuracy: 0.7209\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6775 - binary_accuracy: 0.7319\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6838 - binary_accuracy: 0.7275\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7054 - binary_accuracy: 0.6879\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7100 - binary_accuracy: 0.6857\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6854 - binary_accuracy: 0.7187\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6746 - binary_accuracy: 0.7407\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6730 - binary_accuracy: 0.7385\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6778 - binary_accuracy: 0.7209\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6721 - binary_accuracy: 0.7341\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6785 - binary_accuracy: 0.7077\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6610 - binary_accuracy: 0.7407\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6758 - binary_accuracy: 0.7209\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6563 - binary_accuracy: 0.7648\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6503 - binary_accuracy: 0.7626\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6326 - binary_accuracy: 0.7780\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6955 - binary_accuracy: 0.6967\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7094 - binary_accuracy: 0.6835\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7517 - binary_accuracy: 0.6352\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8040 - binary_accuracy: 0.5670\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7375 - binary_accuracy: 0.6681\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7008 - binary_accuracy: 0.6769\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6758 - binary_accuracy: 0.7385\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6658 - binary_accuracy: 0.7319\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7249 - binary_accuracy: 0.6857\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7329 - binary_accuracy: 0.6747\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7135 - binary_accuracy: 0.6857\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6868 - binary_accuracy: 0.7033\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6683 - binary_accuracy: 0.7187\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6537 - binary_accuracy: 0.7319\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6681 - binary_accuracy: 0.7187\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6575 - binary_accuracy: 0.7187\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6473 - binary_accuracy: 0.7495\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6267 - binary_accuracy: 0.7560\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6232 - binary_accuracy: 0.7560\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.7692\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6563 - binary_accuracy: 0.7429\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6095 - binary_accuracy: 0.7780\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6555 - binary_accuracy: 0.7341\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6280 - binary_accuracy: 0.7692\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7238 - binary_accuracy: 0.6593\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6988 - binary_accuracy: 0.6879\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6890 - binary_accuracy: 0.7011\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6580 - binary_accuracy: 0.7451\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6682 - binary_accuracy: 0.7231\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6248 - binary_accuracy: 0.7780\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.7473\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6390 - binary_accuracy: 0.7473\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6188 - binary_accuracy: 0.7802\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.7626\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.7407\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.7868\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_accuracy: 0.7407\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6071 - binary_accuracy: 0.7846\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.7670\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6359 - binary_accuracy: 0.7538\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.7582\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6288 - binary_accuracy: 0.7582\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6042 - binary_accuracy: 0.7934\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.7582\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6553 - binary_accuracy: 0.7231\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6702 - binary_accuracy: 0.7143\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6430 - binary_accuracy: 0.7451\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6004 - binary_accuracy: 0.7868\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6078 - binary_accuracy: 0.7824\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.7670\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.7758\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6145 - binary_accuracy: 0.7714\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.7626\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.7846\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5899 - binary_accuracy: 0.7890\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8992 - binary_accuracy: 0.5516\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8875 - binary_accuracy: 0.5912\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8790 - binary_accuracy: 0.5978\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8722 - binary_accuracy: 0.5978\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8597 - binary_accuracy: 0.5978\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8483 - binary_accuracy: 0.5978\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8383 - binary_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8311 - binary_accuracy: 0.5956\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8254 - binary_accuracy: 0.5956\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8147 - binary_accuracy: 0.6044\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8137 - binary_accuracy: 0.6132\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7927 - binary_accuracy: 0.6242\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7747 - binary_accuracy: 0.6615\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7589 - binary_accuracy: 0.7209\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7473 - binary_accuracy: 0.7209\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7721 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7666 - binary_accuracy: 0.6923\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7272 - binary_accuracy: 0.7516\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6985 - binary_accuracy: 0.7912\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6918 - binary_accuracy: 0.7934\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6799 - binary_accuracy: 0.8044\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7204 - binary_accuracy: 0.7341\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6942 - binary_accuracy: 0.7692\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6749 - binary_accuracy: 0.7846\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6909 - binary_accuracy: 0.7495\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6759 - binary_accuracy: 0.7714\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7001 - binary_accuracy: 0.7407\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6651 - binary_accuracy: 0.7824\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7126 - binary_accuracy: 0.7231\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7418 - binary_accuracy: 0.6835\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6617 - binary_accuracy: 0.7912\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6689 - binary_accuracy: 0.7604\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6265 - binary_accuracy: 0.8308\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6180 - binary_accuracy: 0.8088\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.8088\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6389 - binary_accuracy: 0.7824\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6158 - binary_accuracy: 0.8154\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6086 - binary_accuracy: 0.8176\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6275 - binary_accuracy: 0.8044\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.7912\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6464 - binary_accuracy: 0.7758\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6361 - binary_accuracy: 0.7824\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6635 - binary_accuracy: 0.7670\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6624 - binary_accuracy: 0.7648\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6803 - binary_accuracy: 0.7275\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6114 - binary_accuracy: 0.8110\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6355 - binary_accuracy: 0.7802\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6096 - binary_accuracy: 0.8154\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6327 - binary_accuracy: 0.7912\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6329 - binary_accuracy: 0.7802\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6259 - binary_accuracy: 0.7824\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6007 - binary_accuracy: 0.8154\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6114 - binary_accuracy: 0.8110\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6085 - binary_accuracy: 0.8066\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5984 - binary_accuracy: 0.8198\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.8044\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6191 - binary_accuracy: 0.8022\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.8264\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6727 - binary_accuracy: 0.7429\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6151 - binary_accuracy: 0.7934\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7798 - binary_accuracy: 0.6022\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7675 - binary_accuracy: 0.6505\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6350 - binary_accuracy: 0.7846\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6144 - binary_accuracy: 0.8176\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6011 - binary_accuracy: 0.8110\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5837 - binary_accuracy: 0.8330\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5867 - binary_accuracy: 0.8330\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5968 - binary_accuracy: 0.8132\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5826 - binary_accuracy: 0.8308\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5763 - binary_accuracy: 0.8396\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6041 - binary_accuracy: 0.8044\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6708 - binary_accuracy: 0.7363\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6104 - binary_accuracy: 0.8088\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6807 - binary_accuracy: 0.7253\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6111 - binary_accuracy: 0.8022\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.8132\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6036 - binary_accuracy: 0.8044\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5978 - binary_accuracy: 0.8088\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6011 - binary_accuracy: 0.8110\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.8022\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5701 - binary_accuracy: 0.8484\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5644 - binary_accuracy: 0.8505\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5910 - binary_accuracy: 0.8132\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5818 - binary_accuracy: 0.8264\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6139 - binary_accuracy: 0.7890\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5915 - binary_accuracy: 0.8352\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6006 - binary_accuracy: 0.8154\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6571 - binary_accuracy: 0.7582\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.7868\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6613 - binary_accuracy: 0.7560\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6147 - binary_accuracy: 0.7978\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6019 - binary_accuracy: 0.8066\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5748 - binary_accuracy: 0.8352\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6593 - binary_accuracy: 0.7516\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6679 - binary_accuracy: 0.7385\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6219 - binary_accuracy: 0.7846\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6844 - binary_accuracy: 0.7187\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8655 - binary_accuracy: 0.5451\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8263 - binary_accuracy: 0.5802\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.9068 - binary_accuracy: 0.5219\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8993 - binary_accuracy: 0.5877\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8957 - binary_accuracy: 0.5833\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8865 - binary_accuracy: 0.5965\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8814 - binary_accuracy: 0.5921\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8749 - binary_accuracy: 0.5921\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8694 - binary_accuracy: 0.5921\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8643 - binary_accuracy: 0.5899\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8552 - binary_accuracy: 0.5921\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8530 - binary_accuracy: 0.5921\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8494 - binary_accuracy: 0.5921\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8458 - binary_accuracy: 0.5921\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8445 - binary_accuracy: 0.5921\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8402 - binary_accuracy: 0.5921\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8363 - binary_accuracy: 0.5921\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8387 - binary_accuracy: 0.5921\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8396 - binary_accuracy: 0.5921\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8388 - binary_accuracy: 0.5921\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8355 - binary_accuracy: 0.5921\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8298 - binary_accuracy: 0.5921\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8331 - binary_accuracy: 0.5921\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8323 - binary_accuracy: 0.5921\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8308 - binary_accuracy: 0.5921\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8306 - binary_accuracy: 0.5921\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8318 - binary_accuracy: 0.5921\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8255 - binary_accuracy: 0.5921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8262 - binary_accuracy: 0.5921\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8230 - binary_accuracy: 0.5899\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8260 - binary_accuracy: 0.5921\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8248 - binary_accuracy: 0.5921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8248 - binary_accuracy: 0.5921\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8241 - binary_accuracy: 0.5921\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8253 - binary_accuracy: 0.5899\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8243 - binary_accuracy: 0.5921\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8240 - binary_accuracy: 0.5921\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8234 - binary_accuracy: 0.5921\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8208 - binary_accuracy: 0.5921\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8212 - binary_accuracy: 0.5943\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8220 - binary_accuracy: 0.5921\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8184 - binary_accuracy: 0.5921\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8223 - binary_accuracy: 0.5899\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8219 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8222 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8214 - binary_accuracy: 0.5921\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8220 - binary_accuracy: 0.5921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8196 - binary_accuracy: 0.5921\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8184 - binary_accuracy: 0.5921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8186 - binary_accuracy: 0.5921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8216 - binary_accuracy: 0.5921\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8194 - binary_accuracy: 0.5921\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8212 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8202 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8210 - binary_accuracy: 0.5921\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8194 - binary_accuracy: 0.5921\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8195 - binary_accuracy: 0.5921\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8196 - binary_accuracy: 0.5921\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8176 - binary_accuracy: 0.5921\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8184 - binary_accuracy: 0.5921\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8171 - binary_accuracy: 0.5921\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8186 - binary_accuracy: 0.5921\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8203 - binary_accuracy: 0.5921\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8181 - binary_accuracy: 0.5921\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8201 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8186 - binary_accuracy: 0.5921\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8187 - binary_accuracy: 0.5921\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8178 - binary_accuracy: 0.5921\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8191 - binary_accuracy: 0.5921\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8170 - binary_accuracy: 0.5921\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8180 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8170 - binary_accuracy: 0.5921\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8183 - binary_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8168 - binary_accuracy: 0.5921\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8172 - binary_accuracy: 0.5921\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8179 - binary_accuracy: 0.5921\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8169 - binary_accuracy: 0.5921\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8177 - binary_accuracy: 0.5921\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8134 - binary_accuracy: 0.5921\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8169 - binary_accuracy: 0.5921\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8187 - binary_accuracy: 0.5899\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8226 - binary_accuracy: 0.5877\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8130 - binary_accuracy: 0.5943\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8153 - binary_accuracy: 0.5987\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8102 - binary_accuracy: 0.5921\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8166 - binary_accuracy: 0.5921\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.5899\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8207 - binary_accuracy: 0.5855\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8136 - binary_accuracy: 0.5877\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8089 - binary_accuracy: 0.5965\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8233 - binary_accuracy: 0.5789\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8142 - binary_accuracy: 0.6009\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8127 - binary_accuracy: 0.5921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8221 - binary_accuracy: 0.5921\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8202 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.5943\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8168 - binary_accuracy: 0.5965\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8178 - binary_accuracy: 0.5921\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8202 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8172 - binary_accuracy: 0.5943\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8174 - binary_accuracy: 0.5943\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8191 - binary_accuracy: 0.5943\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.8197 - binary_accuracy: 0.4484\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8063 - binary_accuracy: 0.6264\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7942 - binary_accuracy: 0.6703\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7821 - binary_accuracy: 0.6769\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7731 - binary_accuracy: 0.6813\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7642 - binary_accuracy: 0.6813\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7542 - binary_accuracy: 0.6747\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7405 - binary_accuracy: 0.6857\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7381 - binary_accuracy: 0.6791\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7296 - binary_accuracy: 0.6791\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7255 - binary_accuracy: 0.6813\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7175 - binary_accuracy: 0.6835\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7137 - binary_accuracy: 0.6857\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7135 - binary_accuracy: 0.6835\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7101 - binary_accuracy: 0.6879\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7120 - binary_accuracy: 0.6835\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7012 - binary_accuracy: 0.6813\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7049 - binary_accuracy: 0.6835\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7023 - binary_accuracy: 0.6791\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6951 - binary_accuracy: 0.6813\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6933 - binary_accuracy: 0.6791\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6993 - binary_accuracy: 0.6835\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6912 - binary_accuracy: 0.6813\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6864 - binary_accuracy: 0.6857\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6854 - binary_accuracy: 0.6835\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6832 - binary_accuracy: 0.6857\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6827 - binary_accuracy: 0.6835\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6815 - binary_accuracy: 0.6835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6828 - binary_accuracy: 0.6791\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6813 - binary_accuracy: 0.6857\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6773 - binary_accuracy: 0.6879\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6782 - binary_accuracy: 0.6813\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6779 - binary_accuracy: 0.6835\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6737 - binary_accuracy: 0.6835\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6730 - binary_accuracy: 0.6835\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6729 - binary_accuracy: 0.6857\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6681 - binary_accuracy: 0.6857\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6718 - binary_accuracy: 0.6835\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6732 - binary_accuracy: 0.6835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6681 - binary_accuracy: 0.6813\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6701 - binary_accuracy: 0.6857\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6679 - binary_accuracy: 0.6857\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6711 - binary_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6651 - binary_accuracy: 0.6857\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6644 - binary_accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6670 - binary_accuracy: 0.6857\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6693 - binary_accuracy: 0.6857\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6644 - binary_accuracy: 0.6835\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6669 - binary_accuracy: 0.6813\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6662 - binary_accuracy: 0.6835\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6622 - binary_accuracy: 0.6835\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6597 - binary_accuracy: 0.6835\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6657 - binary_accuracy: 0.6835\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6623 - binary_accuracy: 0.6813\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6591 - binary_accuracy: 0.6857\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6627 - binary_accuracy: 0.6857\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6582 - binary_accuracy: 0.6835\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6586 - binary_accuracy: 0.6857\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6638 - binary_accuracy: 0.6857\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6600 - binary_accuracy: 0.6813\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6598 - binary_accuracy: 0.6835\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6595 - binary_accuracy: 0.6835\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6560 - binary_accuracy: 0.6835\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6536 - binary_accuracy: 0.6813\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6559 - binary_accuracy: 0.6835\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6581 - binary_accuracy: 0.6813\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6557 - binary_accuracy: 0.6835\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6581 - binary_accuracy: 0.6835\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6591 - binary_accuracy: 0.6857\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6857\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6513 - binary_accuracy: 0.6857\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6537 - binary_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6551 - binary_accuracy: 0.6813\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6515 - binary_accuracy: 0.6835\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6494 - binary_accuracy: 0.6857\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6522 - binary_accuracy: 0.6835\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6516 - binary_accuracy: 0.6813\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.6835\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6480 - binary_accuracy: 0.6857\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.6835\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6511 - binary_accuracy: 0.6857\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6505 - binary_accuracy: 0.6879\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6531 - binary_accuracy: 0.6835\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6517 - binary_accuracy: 0.6857\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6504 - binary_accuracy: 0.6835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6512 - binary_accuracy: 0.6857\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6525 - binary_accuracy: 0.6835\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6509 - binary_accuracy: 0.6857\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6474 - binary_accuracy: 0.6879\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6503 - binary_accuracy: 0.6857\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6518 - binary_accuracy: 0.6835\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6835\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6506 - binary_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6504 - binary_accuracy: 0.6813\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6464 - binary_accuracy: 0.6879\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6505 - binary_accuracy: 0.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6520 - binary_accuracy: 0.6813\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.8542 - binary_accuracy: 0.5275\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8392 - binary_accuracy: 0.6044\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8317 - binary_accuracy: 0.6308\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8284 - binary_accuracy: 0.6352\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8203 - binary_accuracy: 0.6418\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8146 - binary_accuracy: 0.6352\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8089 - binary_accuracy: 0.6418\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8035 - binary_accuracy: 0.6374\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8050 - binary_accuracy: 0.6418\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8007 - binary_accuracy: 0.6396\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7924 - binary_accuracy: 0.6440\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7921 - binary_accuracy: 0.6396\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7848 - binary_accuracy: 0.6396\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7865 - binary_accuracy: 0.6396\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7799 - binary_accuracy: 0.6418\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7823 - binary_accuracy: 0.6418\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7776 - binary_accuracy: 0.6418\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7775 - binary_accuracy: 0.6418\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7760 - binary_accuracy: 0.6418\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7694 - binary_accuracy: 0.6418\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7672 - binary_accuracy: 0.6418\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7693 - binary_accuracy: 0.6418\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7686 - binary_accuracy: 0.6418\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7606 - binary_accuracy: 0.6418\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7634 - binary_accuracy: 0.6418\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7619 - binary_accuracy: 0.6418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7639 - binary_accuracy: 0.6418\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7577 - binary_accuracy: 0.6418\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7592 - binary_accuracy: 0.6418\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7590 - binary_accuracy: 0.6418\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7547 - binary_accuracy: 0.6418\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7546 - binary_accuracy: 0.6418\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7532 - binary_accuracy: 0.6418\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7550 - binary_accuracy: 0.6418\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7527 - binary_accuracy: 0.6418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7536 - binary_accuracy: 0.6418\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7489 - binary_accuracy: 0.6418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - binary_accuracy: 0.6418\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7501 - binary_accuracy: 0.6418\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7476 - binary_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7466 - binary_accuracy: 0.6418\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7517 - binary_accuracy: 0.6418\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7478 - binary_accuracy: 0.6418\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7454 - binary_accuracy: 0.6418\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7438 - binary_accuracy: 0.6418\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7475 - binary_accuracy: 0.6418\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - binary_accuracy: 0.6418\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7420 - binary_accuracy: 0.6418\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7440 - binary_accuracy: 0.6418\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7425 - binary_accuracy: 0.6418\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7401 - binary_accuracy: 0.6418\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7365 - binary_accuracy: 0.6418\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - binary_accuracy: 0.6418\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7418 - binary_accuracy: 0.6418\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7410 - binary_accuracy: 0.6418\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7394 - binary_accuracy: 0.6418\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7367 - binary_accuracy: 0.6418\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7384 - binary_accuracy: 0.6418\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7391 - binary_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7388 - binary_accuracy: 0.6418\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7357 - binary_accuracy: 0.6418\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7377 - binary_accuracy: 0.6418\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7412 - binary_accuracy: 0.6418\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7379 - binary_accuracy: 0.6418\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7357 - binary_accuracy: 0.6440\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7355 - binary_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7341 - binary_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7369 - binary_accuracy: 0.6418\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7376 - binary_accuracy: 0.6418\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7344 - binary_accuracy: 0.6418\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7366 - binary_accuracy: 0.6418\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7337 - binary_accuracy: 0.6418\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7338 - binary_accuracy: 0.6418\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7325 - binary_accuracy: 0.6418\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7340 - binary_accuracy: 0.6418\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7347 - binary_accuracy: 0.6418\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7322 - binary_accuracy: 0.6418\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7308 - binary_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7300 - binary_accuracy: 0.6418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7290 - binary_accuracy: 0.6418\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7312 - binary_accuracy: 0.6418\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7314 - binary_accuracy: 0.6418\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7307 - binary_accuracy: 0.6418\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7299 - binary_accuracy: 0.6418\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7309 - binary_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7303 - binary_accuracy: 0.6418\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7300 - binary_accuracy: 0.6418\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7287 - binary_accuracy: 0.6418\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7269 - binary_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7288 - binary_accuracy: 0.6418\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7306 - binary_accuracy: 0.6418\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7306 - binary_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7298 - binary_accuracy: 0.6418\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7267 - binary_accuracy: 0.6418\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7280 - binary_accuracy: 0.6418\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7278 - binary_accuracy: 0.6418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7273 - binary_accuracy: 0.6418\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7302 - binary_accuracy: 0.6418\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7273 - binary_accuracy: 0.6418\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7293 - binary_accuracy: 0.6418\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8593 - binary_accuracy: 0.6088\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8501 - binary_accuracy: 0.6044\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8443 - binary_accuracy: 0.6110\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8384 - binary_accuracy: 0.6066\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8305 - binary_accuracy: 0.6110\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8276 - binary_accuracy: 0.6132\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8341 - binary_accuracy: 0.6088\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8265 - binary_accuracy: 0.6066\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8194 - binary_accuracy: 0.6088\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8154 - binary_accuracy: 0.6110\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8133 - binary_accuracy: 0.6088\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8069 - binary_accuracy: 0.6110\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8030 - binary_accuracy: 0.6110\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8116 - binary_accuracy: 0.6088\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8045 - binary_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8010 - binary_accuracy: 0.6088\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8018 - binary_accuracy: 0.6110\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8016 - binary_accuracy: 0.6088\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8014 - binary_accuracy: 0.6154\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7923 - binary_accuracy: 0.6110\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7985 - binary_accuracy: 0.6110\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7973 - binary_accuracy: 0.6176\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7967 - binary_accuracy: 0.6132\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7942 - binary_accuracy: 0.6132\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7927 - binary_accuracy: 0.6154\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7898 - binary_accuracy: 0.6176\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7863 - binary_accuracy: 0.6110\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7841 - binary_accuracy: 0.6132\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7879 - binary_accuracy: 0.6110\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7896 - binary_accuracy: 0.6132\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7844 - binary_accuracy: 0.6132\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7853 - binary_accuracy: 0.6132\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7853 - binary_accuracy: 0.6132\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7866 - binary_accuracy: 0.6154\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7878 - binary_accuracy: 0.6132\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7848 - binary_accuracy: 0.6176\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7809 - binary_accuracy: 0.6154\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7843 - binary_accuracy: 0.6198\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7832 - binary_accuracy: 0.6154\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7774 - binary_accuracy: 0.6154\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7830 - binary_accuracy: 0.6176\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7806 - binary_accuracy: 0.6132\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7817 - binary_accuracy: 0.6198\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7859 - binary_accuracy: 0.6154\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7798 - binary_accuracy: 0.6154\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7815 - binary_accuracy: 0.6110\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7800 - binary_accuracy: 0.6154\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7806 - binary_accuracy: 0.6154\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7823 - binary_accuracy: 0.6154\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7793 - binary_accuracy: 0.6198\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7770 - binary_accuracy: 0.6154\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7757 - binary_accuracy: 0.6198\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7817 - binary_accuracy: 0.6154\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7722 - binary_accuracy: 0.6198\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7752 - binary_accuracy: 0.6198\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7777 - binary_accuracy: 0.6132\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7756 - binary_accuracy: 0.6176\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7775 - binary_accuracy: 0.6154\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7783 - binary_accuracy: 0.6176\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7784 - binary_accuracy: 0.6110\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7804 - binary_accuracy: 0.6154\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7738 - binary_accuracy: 0.6176\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7771 - binary_accuracy: 0.6176\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7749 - binary_accuracy: 0.6176\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7769 - binary_accuracy: 0.6176\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7743 - binary_accuracy: 0.6110\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7744 - binary_accuracy: 0.6198\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7779 - binary_accuracy: 0.6198\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7764 - binary_accuracy: 0.6176\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7742 - binary_accuracy: 0.6198\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7741 - binary_accuracy: 0.6176\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7748 - binary_accuracy: 0.6198\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7730 - binary_accuracy: 0.6198\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7710 - binary_accuracy: 0.6220\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7673 - binary_accuracy: 0.6198\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7745 - binary_accuracy: 0.6198\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7741 - binary_accuracy: 0.6110\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7698 - binary_accuracy: 0.6220\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7704 - binary_accuracy: 0.6198\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7702 - binary_accuracy: 0.6198\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7752 - binary_accuracy: 0.6154\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7727 - binary_accuracy: 0.6220\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7751 - binary_accuracy: 0.6198\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7680 - binary_accuracy: 0.6220\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7728 - binary_accuracy: 0.6220\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7737 - binary_accuracy: 0.6176\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7736 - binary_accuracy: 0.6198\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7755 - binary_accuracy: 0.6154\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7718 - binary_accuracy: 0.6198\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7735 - binary_accuracy: 0.6198\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7736 - binary_accuracy: 0.6176\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7732 - binary_accuracy: 0.6176\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7719 - binary_accuracy: 0.6176\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7740 - binary_accuracy: 0.6198\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7734 - binary_accuracy: 0.6176\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7692 - binary_accuracy: 0.6198\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7710 - binary_accuracy: 0.6154\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7700 - binary_accuracy: 0.6198\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7719 - binary_accuracy: 0.6220\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7709 - binary_accuracy: 0.6220\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.8950 - binary_accuracy: 0.5516\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8896 - binary_accuracy: 0.5670\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8844 - binary_accuracy: 0.5780\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8812 - binary_accuracy: 0.5868\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8778 - binary_accuracy: 0.5934\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8760 - binary_accuracy: 0.5934\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8742 - binary_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8676 - binary_accuracy: 0.5978\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8645 - binary_accuracy: 0.5978\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8647 - binary_accuracy: 0.5978\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8543 - binary_accuracy: 0.5978\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8569 - binary_accuracy: 0.5978\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8553 - binary_accuracy: 0.5978\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8503 - binary_accuracy: 0.5978\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8481 - binary_accuracy: 0.5978\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8505 - binary_accuracy: 0.5978\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8435 - binary_accuracy: 0.5978\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8437 - binary_accuracy: 0.5978\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8416 - binary_accuracy: 0.5978\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8375 - binary_accuracy: 0.5978\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8449 - binary_accuracy: 0.5978\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8407 - binary_accuracy: 0.5978\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8376 - binary_accuracy: 0.5978\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8397 - binary_accuracy: 0.5978\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8354 - binary_accuracy: 0.5978\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8335 - binary_accuracy: 0.5978\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8380 - binary_accuracy: 0.5978\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8280 - binary_accuracy: 0.5978\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8347 - binary_accuracy: 0.5978\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8311 - binary_accuracy: 0.5978\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8278 - binary_accuracy: 0.5978\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8300 - binary_accuracy: 0.5978\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8290 - binary_accuracy: 0.5978\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8250 - binary_accuracy: 0.5978\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8268 - binary_accuracy: 0.5978\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8226 - binary_accuracy: 0.5978\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8235 - binary_accuracy: 0.5978\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8283 - binary_accuracy: 0.5978\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8296 - binary_accuracy: 0.5978\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8263 - binary_accuracy: 0.5978\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8242 - binary_accuracy: 0.5978\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8208 - binary_accuracy: 0.5978\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8231 - binary_accuracy: 0.5978\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8282 - binary_accuracy: 0.5978\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8238 - binary_accuracy: 0.5978\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8219 - binary_accuracy: 0.5978\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8242 - binary_accuracy: 0.5978\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8243 - binary_accuracy: 0.5978\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8192 - binary_accuracy: 0.5978\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8239 - binary_accuracy: 0.5978\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8170 - binary_accuracy: 0.5978\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8216 - binary_accuracy: 0.5978\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8204 - binary_accuracy: 0.5978\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8225 - binary_accuracy: 0.5978\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8177 - binary_accuracy: 0.5978\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8179 - binary_accuracy: 0.5978\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8135 - binary_accuracy: 0.5978\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8194 - binary_accuracy: 0.5978\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8170 - binary_accuracy: 0.5978\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8212 - binary_accuracy: 0.5978\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8187 - binary_accuracy: 0.5978\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8187 - binary_accuracy: 0.5978\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8165 - binary_accuracy: 0.5978\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8134 - binary_accuracy: 0.5978\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8182 - binary_accuracy: 0.5978\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8145 - binary_accuracy: 0.5978\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8171 - binary_accuracy: 0.5978\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8154 - binary_accuracy: 0.5978\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8154 - binary_accuracy: 0.5978\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8212 - binary_accuracy: 0.5978\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8167 - binary_accuracy: 0.5978\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8145 - binary_accuracy: 0.5978\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8149 - binary_accuracy: 0.5978\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8178 - binary_accuracy: 0.5978\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8132 - binary_accuracy: 0.5978\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8190 - binary_accuracy: 0.5978\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8170 - binary_accuracy: 0.5978\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8156 - binary_accuracy: 0.5978\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8131 - binary_accuracy: 0.5978\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8138 - binary_accuracy: 0.5978\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8119 - binary_accuracy: 0.5978\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8130 - binary_accuracy: 0.5978\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8139 - binary_accuracy: 0.5978\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8140 - binary_accuracy: 0.5978\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8145 - binary_accuracy: 0.5978\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8129 - binary_accuracy: 0.5978\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8145 - binary_accuracy: 0.5978\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8091 - binary_accuracy: 0.5978\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8131 - binary_accuracy: 0.5978\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8130 - binary_accuracy: 0.5978\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8131 - binary_accuracy: 0.5978\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8091 - binary_accuracy: 0.5978\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8139 - binary_accuracy: 0.5978\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8092 - binary_accuracy: 0.5978\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8131 - binary_accuracy: 0.5978\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8130 - binary_accuracy: 0.5978\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8158 - binary_accuracy: 0.5978\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8127 - binary_accuracy: 0.5978\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8112 - binary_accuracy: 0.5978\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 4ms/step - loss: 0.9220 - binary_accuracy: 0.4189\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.9139 - binary_accuracy: 0.4452\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9168 - binary_accuracy: 0.4364\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9106 - binary_accuracy: 0.4868\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.9069 - binary_accuracy: 0.4978\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9027 - binary_accuracy: 0.5461\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8982 - binary_accuracy: 0.5702\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8974 - binary_accuracy: 0.5855\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8954 - binary_accuracy: 0.5833\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8982 - binary_accuracy: 0.5614\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8977 - binary_accuracy: 0.5724\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8933 - binary_accuracy: 0.6009\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8938 - binary_accuracy: 0.5899\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8923 - binary_accuracy: 0.6009\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8882 - binary_accuracy: 0.5899\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8951 - binary_accuracy: 0.5811\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8910 - binary_accuracy: 0.5746\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8886 - binary_accuracy: 0.5702\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8889 - binary_accuracy: 0.5833\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8868 - binary_accuracy: 0.5921\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8849 - binary_accuracy: 0.5921\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8869 - binary_accuracy: 0.5899\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8852 - binary_accuracy: 0.5877\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8763 - binary_accuracy: 0.5921\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8801 - binary_accuracy: 0.5921\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8781 - binary_accuracy: 0.5921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8730 - binary_accuracy: 0.5921\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8762 - binary_accuracy: 0.5921\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8742 - binary_accuracy: 0.5921\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8720 - binary_accuracy: 0.5921\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8689 - binary_accuracy: 0.5921\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8675 - binary_accuracy: 0.5921\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8656 - binary_accuracy: 0.5921\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8644 - binary_accuracy: 0.5921\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8670 - binary_accuracy: 0.5921\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8648 - binary_accuracy: 0.5921\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8613 - binary_accuracy: 0.5921\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8600 - binary_accuracy: 0.5921\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8650 - binary_accuracy: 0.5921\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8631 - binary_accuracy: 0.5921\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8565 - binary_accuracy: 0.5921\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8585 - binary_accuracy: 0.5921\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8593 - binary_accuracy: 0.5921\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8568 - binary_accuracy: 0.5921\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8595 - binary_accuracy: 0.5921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8537 - binary_accuracy: 0.5921\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8546 - binary_accuracy: 0.5921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8517 - binary_accuracy: 0.5921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8503 - binary_accuracy: 0.5921\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8552 - binary_accuracy: 0.5921\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8566 - binary_accuracy: 0.5921\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8530 - binary_accuracy: 0.5921\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8554 - binary_accuracy: 0.5921\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8511 - binary_accuracy: 0.5921\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8506 - binary_accuracy: 0.5921\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8493 - binary_accuracy: 0.5921\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8496 - binary_accuracy: 0.5921\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8487 - binary_accuracy: 0.5921\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8480 - binary_accuracy: 0.5921\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8471 - binary_accuracy: 0.5921\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8488 - binary_accuracy: 0.5921\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8486 - binary_accuracy: 0.5921\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8501 - binary_accuracy: 0.5921\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8538 - binary_accuracy: 0.5921\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8463 - binary_accuracy: 0.5921\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8430 - binary_accuracy: 0.5921\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8460 - binary_accuracy: 0.5921\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8459 - binary_accuracy: 0.5921\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8466 - binary_accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8424 - binary_accuracy: 0.5921\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8405 - binary_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8469 - binary_accuracy: 0.5921\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8448 - binary_accuracy: 0.5921\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8438 - binary_accuracy: 0.5921\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8379 - binary_accuracy: 0.5921\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8406 - binary_accuracy: 0.5921\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8384 - binary_accuracy: 0.5921\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8435 - binary_accuracy: 0.5921\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8465 - binary_accuracy: 0.5921\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8444 - binary_accuracy: 0.5921\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8338 - binary_accuracy: 0.5921\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8396 - binary_accuracy: 0.5921\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8420 - binary_accuracy: 0.5921\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8406 - binary_accuracy: 0.5921\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8355 - binary_accuracy: 0.5921\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8444 - binary_accuracy: 0.5921\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8388 - binary_accuracy: 0.5921\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8382 - binary_accuracy: 0.5921\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8354 - binary_accuracy: 0.5921\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8375 - binary_accuracy: 0.5921\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8353 - binary_accuracy: 0.5921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8389 - binary_accuracy: 0.5921\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8373 - binary_accuracy: 0.5921\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8359 - binary_accuracy: 0.5921\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8309 - binary_accuracy: 0.5921\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8360 - binary_accuracy: 0.5921\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8383 - binary_accuracy: 0.5921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8337 - binary_accuracy: 0.5921\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8352 - binary_accuracy: 0.5921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8367 - binary_accuracy: 0.5921\n",
            "Epoch 1/100\n",
            "57/57 [==============================] - 1s 4ms/step - loss: 1.1448 - binary_accuracy: 0.5852\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6002 - binary_accuracy: 0.6573\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5430 - binary_accuracy: 0.7030\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5679 - binary_accuracy: 0.6819\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5231 - binary_accuracy: 0.7118\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.5042 - binary_accuracy: 0.7698\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4863 - binary_accuracy: 0.7557\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4716 - binary_accuracy: 0.7926\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.4375 - binary_accuracy: 0.8120\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4675 - binary_accuracy: 0.7627\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4604 - binary_accuracy: 0.8049\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4124 - binary_accuracy: 0.8207\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.7996\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4064 - binary_accuracy: 0.8190\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3971 - binary_accuracy: 0.8313\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.4034 - binary_accuracy: 0.8207\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.8278\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8330\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3762 - binary_accuracy: 0.8243\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3786 - binary_accuracy: 0.8243\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8401\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8401\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3655 - binary_accuracy: 0.8366\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8401\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3673 - binary_accuracy: 0.8436\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8524\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8418\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3726 - binary_accuracy: 0.8295\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3719 - binary_accuracy: 0.8243\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8383\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8471\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8401\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8489\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8436\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3419 - binary_accuracy: 0.8524\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8436\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3355 - binary_accuracy: 0.8489\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3466 - binary_accuracy: 0.8348\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8453\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3550 - binary_accuracy: 0.8348\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3456 - binary_accuracy: 0.8366\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3042 - binary_accuracy: 0.8541\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3141 - binary_accuracy: 0.8506\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8436\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3064 - binary_accuracy: 0.8647\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3077 - binary_accuracy: 0.8506\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3291 - binary_accuracy: 0.8453\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3185 - binary_accuracy: 0.8489\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3163 - binary_accuracy: 0.8576\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3002 - binary_accuracy: 0.8541\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3461 - binary_accuracy: 0.8278\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3470 - binary_accuracy: 0.8207\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3105 - binary_accuracy: 0.8559\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3075 - binary_accuracy: 0.8524\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3128 - binary_accuracy: 0.8576\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3212 - binary_accuracy: 0.8348\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3084 - binary_accuracy: 0.8576\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8559\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8418\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2952 - binary_accuracy: 0.8576\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3095 - binary_accuracy: 0.8594\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3168 - binary_accuracy: 0.8453\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3055 - binary_accuracy: 0.8717\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3043 - binary_accuracy: 0.8576\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3095 - binary_accuracy: 0.8401\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2961 - binary_accuracy: 0.8594\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3171 - binary_accuracy: 0.8330\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3086 - binary_accuracy: 0.8330\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3158 - binary_accuracy: 0.8366\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8471\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3067 - binary_accuracy: 0.8524\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3156 - binary_accuracy: 0.8506\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3360 - binary_accuracy: 0.8278\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3306 - binary_accuracy: 0.8295\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3043 - binary_accuracy: 0.8506\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2859 - binary_accuracy: 0.8541\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2918 - binary_accuracy: 0.8524\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3193 - binary_accuracy: 0.8576\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2877 - binary_accuracy: 0.8541\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3107 - binary_accuracy: 0.8541\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2727 - binary_accuracy: 0.8752\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3245 - binary_accuracy: 0.8489\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3081 - binary_accuracy: 0.8629\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2789 - binary_accuracy: 0.8664\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2758 - binary_accuracy: 0.8576\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2854 - binary_accuracy: 0.8612\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2820 - binary_accuracy: 0.8735\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8313\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3065 - binary_accuracy: 0.8541\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.2750 - binary_accuracy: 0.8858\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3247 - binary_accuracy: 0.8436\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3259 - binary_accuracy: 0.8383\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2950 - binary_accuracy: 0.8506\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2830 - binary_accuracy: 0.8629\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3243 - binary_accuracy: 0.8330\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.3179 - binary_accuracy: 0.8401\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2811 - binary_accuracy: 0.8576\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2704 - binary_accuracy: 0.8664\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.3129 - binary_accuracy: 0.8366\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2805 - binary_accuracy: 0.8752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6cE19xAcAW-",
        "outputId": "e01216d6-3e54-4a8e-9012-c4efbe65df4b"
      },
      "source": [
        "grid_search"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc0e8d79f10>,\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['relu', 'tanh'], 'batch_size': [10, 30],\n",
              "                         'epochs': [50, 100],\n",
              "                         'kernel_initializer': ['random_uniform', 'normal'],\n",
              "                         'loss': ['binary_crossentropy', 'hinge'],\n",
              "                         'neurons': [16, 8], 'optimizer': ['adam', 'sgd']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRuvav9mcEi2",
        "outputId": "200542aa-ac97-4c5f-8cca-542656a90ce4"
      },
      "source": [
        "melhores_parametros"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 10,\n",
              " 'epochs': 100,\n",
              " 'kernel_initializer': 'random_uniform',\n",
              " 'loss': 'binary_crossentropy',\n",
              " 'neurons': 8,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_0H50DEcIW-",
        "outputId": "f72c2379-a1a7-42fb-bd32-c3df32c02e01"
      },
      "source": [
        "melhor_precisao"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9104486880919112"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}