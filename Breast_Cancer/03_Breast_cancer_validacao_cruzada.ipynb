{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_cancer_validacao_cruzada.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfpbbRpzXOeO"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "previsores = pd.read_csv('entradas_breast.csv')\n",
        "classe = pd.read_csv('saidas_breast.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "byMgNr9YbHTY",
        "outputId": "7f916f33-e98b-4113-b60e-b6fdc55cff5e"
      },
      "source": [
        "previsores"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.00000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>205.00000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>111.00000</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1176.0000</td>\n",
              "      <td>1256.0000</td>\n",
              "      <td>7673.0</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.45</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>141.00000</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>206.0000</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>144.00000</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2463.0000</td>\n",
              "      <td>5203.0</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.69</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>159.0000</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1075.0000</td>\n",
              "      <td>3425.0</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.98</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>277.00000</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>152.00000</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>726.0000</td>\n",
              "      <td>1595.0000</td>\n",
              "      <td>5772.0</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.74</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>165.00000</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>265.0000</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>124.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1428.0000</td>\n",
              "      <td>2548.0</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9456.00</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0           17.99          10.38  ...           0.4601                   0.11890\n",
              "1           20.57          17.77  ...         275.0000                   0.08902\n",
              "2           19.69          21.25  ...           0.3613                   0.08758\n",
              "3           11.42          20.38  ...           0.6638                 173.00000\n",
              "4           20.29          14.34  ...           0.2364                   0.07678\n",
              "..            ...            ...  ...              ...                       ...\n",
              "564         21.56          22.39  ...         206.0000                   0.07115\n",
              "565         20.13          28.25  ...           0.2572                   0.06637\n",
              "566         16.60          28.08  ...           0.2218                   0.07820\n",
              "567         20.60          29.33  ...           0.4087                 124.00000\n",
              "568          7.76          24.54  ...           0.2871                   0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "VoFEd3c7bRfq",
        "outputId": "912770f4-40d4-4435-95b4-5370b1dca428"
      },
      "source": [
        "classe"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "..  ..\n",
              "564  0\n",
              "565  0\n",
              "566  0\n",
              "567  0\n",
              "568  1\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMCD5ijDbfjY"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def criarRede():\n",
        "  classificador=Sequential()\n",
        "#Primeira camada oculta\n",
        "#Definição da primeira camada de entrada (input_dim)\n",
        "  classificador.add(Dense(units =16, activation= 'relu', kernel_initializer='random_uniform', input_dim=30)) \n",
        "#camada de dropout, passando o parametro da porentagem que eu quero zerar\n",
        "  classificador.add(Dropout(0.2))\n",
        "#Segunda camada oculta  \n",
        "  classificador.add(Dense(units =16, activation= 'relu', kernel_initializer='random_uniform')) \n",
        "  classificador.add(Dropout(0.2))\n",
        "#camada de saida\n",
        "  classificador.add(Dense(units =1, activation= 'sigmoid'))   \n",
        "  otimizador= keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
        "#classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "  classificador.compile(optimizer=otimizador, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "  return classificador"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_uJIAMmh0dr"
      },
      "source": [
        "classificador = KerasClassifier(build_fn =criarRede, epochs=100,batch_size=10)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFFwe8Z1iElu",
        "outputId": "7c1fb8f3-cf29-4a30-b6c7-de1d2bc31cb6"
      },
      "source": [
        "resultados= cross_val_score(estimator=classificador, X=previsores, y=classe, cv=10, scoring='accuracy' )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 0.9486 - binary_accuracy: 0.6035\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6271 - binary_accuracy: 0.6699\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6607 - binary_accuracy: 0.6250\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5499 - binary_accuracy: 0.6348\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5882 - binary_accuracy: 0.6660\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.6758\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6093 - binary_accuracy: 0.7383\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5646 - binary_accuracy: 0.7285\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6085 - binary_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6421 - binary_accuracy: 0.7012\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5692 - binary_accuracy: 0.7539\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5752 - binary_accuracy: 0.7715\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6493 - binary_accuracy: 0.7363\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5223 - binary_accuracy: 0.7656\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5020 - binary_accuracy: 0.7539\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6565 - binary_accuracy: 0.7676\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6574 - binary_accuracy: 0.7754\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5267 - binary_accuracy: 0.7461\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5621 - binary_accuracy: 0.7754\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5196 - binary_accuracy: 0.7812\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.7656\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6144 - binary_accuracy: 0.7715\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5595 - binary_accuracy: 0.7578\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5625 - binary_accuracy: 0.8184\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5924 - binary_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6267 - binary_accuracy: 0.7871\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4832 - binary_accuracy: 0.8086\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6363 - binary_accuracy: 0.8086\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4931 - binary_accuracy: 0.8066\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5379 - binary_accuracy: 0.7969\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5389 - binary_accuracy: 0.8125\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6874 - binary_accuracy: 0.7910\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5425 - binary_accuracy: 0.8027\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5124 - binary_accuracy: 0.8105\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5508 - binary_accuracy: 0.8242\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5003 - binary_accuracy: 0.8164\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_accuracy: 0.8203\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5484 - binary_accuracy: 0.8164\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6476 - binary_accuracy: 0.8047\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5518 - binary_accuracy: 0.8262\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5772 - binary_accuracy: 0.8066\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5927 - binary_accuracy: 0.8379\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5434 - binary_accuracy: 0.8301\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5947 - binary_accuracy: 0.7969\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5124 - binary_accuracy: 0.8242\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4884 - binary_accuracy: 0.8066\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4635 - binary_accuracy: 0.8340\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6529 - binary_accuracy: 0.8105\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5519 - binary_accuracy: 0.8438\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5513 - binary_accuracy: 0.8203\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6520 - binary_accuracy: 0.8164\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4934 - binary_accuracy: 0.8066\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5203 - binary_accuracy: 0.8164\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5397 - binary_accuracy: 0.8184\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6124 - binary_accuracy: 0.8477\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5200 - binary_accuracy: 0.8242\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4621 - binary_accuracy: 0.8203\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5391 - binary_accuracy: 0.8281\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5685 - binary_accuracy: 0.8008\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6377 - binary_accuracy: 0.7969\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.8105\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4936 - binary_accuracy: 0.8105\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4532 - binary_accuracy: 0.8223\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5809 - binary_accuracy: 0.8203\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.8223\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4677 - binary_accuracy: 0.8281\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5427 - binary_accuracy: 0.8203\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4434 - binary_accuracy: 0.8398\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5277 - binary_accuracy: 0.8164\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5101 - binary_accuracy: 0.8262\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4728 - binary_accuracy: 0.8301\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4737 - binary_accuracy: 0.8164\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4826 - binary_accuracy: 0.8145\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4955 - binary_accuracy: 0.8105\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4390 - binary_accuracy: 0.8086\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4258 - binary_accuracy: 0.8457\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4205 - binary_accuracy: 0.8457\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4984 - binary_accuracy: 0.8027\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4354 - binary_accuracy: 0.8496\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4066 - binary_accuracy: 0.8398\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4662 - binary_accuracy: 0.8301\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4877 - binary_accuracy: 0.8320\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5340 - binary_accuracy: 0.8477\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4798 - binary_accuracy: 0.8457\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5123 - binary_accuracy: 0.8223\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3959 - binary_accuracy: 0.8574\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4317 - binary_accuracy: 0.8438\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4159 - binary_accuracy: 0.8535\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9205 - binary_accuracy: 0.8379\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4645 - binary_accuracy: 0.8262\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4041 - binary_accuracy: 0.8574\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5042 - binary_accuracy: 0.8398\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4707 - binary_accuracy: 0.8105\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4668 - binary_accuracy: 0.8516\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.8320\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3965 - binary_accuracy: 0.8574\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4054 - binary_accuracy: 0.8613\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4789 - binary_accuracy: 0.8359\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4910 - binary_accuracy: 0.8438\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4444 - binary_accuracy: 0.8594\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.9816 - binary_accuracy: 0.5469\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6703 - binary_accuracy: 0.6211\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.6406\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6582\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5835 - binary_accuracy: 0.6895\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6186 - binary_accuracy: 0.6914\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5744 - binary_accuracy: 0.7344\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6552 - binary_accuracy: 0.6777\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5503 - binary_accuracy: 0.7520\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6754 - binary_accuracy: 0.7148\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5403 - binary_accuracy: 0.7812\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.7949\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7048 - binary_accuracy: 0.7793\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6149 - binary_accuracy: 0.7832\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5848 - binary_accuracy: 0.7949\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7997 - binary_accuracy: 0.8125\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6131 - binary_accuracy: 0.8066\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6657 - binary_accuracy: 0.7988\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5252 - binary_accuracy: 0.8359\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7021 - binary_accuracy: 0.8105\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5458 - binary_accuracy: 0.8281\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5442 - binary_accuracy: 0.8262\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9266 - binary_accuracy: 0.8340\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6440 - binary_accuracy: 0.7832\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4559 - binary_accuracy: 0.8262\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5364 - binary_accuracy: 0.8281\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5876 - binary_accuracy: 0.8535\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7713 - binary_accuracy: 0.8086\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4919 - binary_accuracy: 0.8301\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8742 - binary_accuracy: 0.8340\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6567 - binary_accuracy: 0.8262\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7419 - binary_accuracy: 0.8223\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6587 - binary_accuracy: 0.8262\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4946 - binary_accuracy: 0.8672\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5966 - binary_accuracy: 0.8516\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4605 - binary_accuracy: 0.8398\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4838 - binary_accuracy: 0.8633\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5840 - binary_accuracy: 0.8496\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0465 - binary_accuracy: 0.8730\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3727 - binary_accuracy: 0.8691\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8867\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6398 - binary_accuracy: 0.8535\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0337 - binary_accuracy: 0.8438\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8462 - binary_accuracy: 0.8613\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9298 - binary_accuracy: 0.8633\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2982 - binary_accuracy: 0.8594\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.1179 - binary_accuracy: 0.8555\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8207 - binary_accuracy: 0.8477\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5611 - binary_accuracy: 0.8457\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8881 - binary_accuracy: 0.8496\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3057 - binary_accuracy: 0.8613\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3187 - binary_accuracy: 0.8691\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4457 - binary_accuracy: 0.8555\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5956 - binary_accuracy: 0.8711\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6218 - binary_accuracy: 0.8691\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5397 - binary_accuracy: 0.8555\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6650 - binary_accuracy: 0.8867\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4108 - binary_accuracy: 0.8789\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9487 - binary_accuracy: 0.8496\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8900 - binary_accuracy: 0.8887\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7518 - binary_accuracy: 0.8789\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0283 - binary_accuracy: 0.8828\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5758 - binary_accuracy: 0.8828\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3624 - binary_accuracy: 0.8691\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.1446 - binary_accuracy: 0.8867\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7755 - binary_accuracy: 0.8770\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9939 - binary_accuracy: 0.8652\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7953 - binary_accuracy: 0.8730\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5092 - binary_accuracy: 0.8730\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9722 - binary_accuracy: 0.8848\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7657 - binary_accuracy: 0.8691\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1443 - binary_accuracy: 0.8574\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.4619 - binary_accuracy: 0.8750\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4195 - binary_accuracy: 0.8633\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3050 - binary_accuracy: 0.8438\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0754 - binary_accuracy: 0.8496\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4689 - binary_accuracy: 0.8477\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2653 - binary_accuracy: 0.8809\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7036 - binary_accuracy: 0.8457\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5233 - binary_accuracy: 0.8730\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.1253 - binary_accuracy: 0.8691\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0301 - binary_accuracy: 0.8672\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3766 - binary_accuracy: 0.8281\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5833 - binary_accuracy: 0.8848\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.2135 - binary_accuracy: 0.8770\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3459 - binary_accuracy: 0.8828\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5718 - binary_accuracy: 0.8770\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8671 - binary_accuracy: 0.8848\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3996 - binary_accuracy: 0.8711\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6915 - binary_accuracy: 0.8809\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7647 - binary_accuracy: 0.8633\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9339 - binary_accuracy: 0.8652\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8086 - binary_accuracy: 0.8906\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0606 - binary_accuracy: 0.8789\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5809 - binary_accuracy: 0.8848\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.7898 - binary_accuracy: 0.8691\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7819 - binary_accuracy: 0.8828\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6850 - binary_accuracy: 0.8828\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8158 - binary_accuracy: 0.8809\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6059 - binary_accuracy: 0.8750\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.2571 - binary_accuracy: 0.6211\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7426 - binary_accuracy: 0.7012\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6119 - binary_accuracy: 0.6934\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6622 - binary_accuracy: 0.7207\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5860 - binary_accuracy: 0.7441\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6684 - binary_accuracy: 0.7207\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.7305\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6018 - binary_accuracy: 0.7480\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6254 - binary_accuracy: 0.7578\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5431 - binary_accuracy: 0.7578\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5504 - binary_accuracy: 0.7363\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5610 - binary_accuracy: 0.7734\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5825 - binary_accuracy: 0.7754\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5424 - binary_accuracy: 0.7656\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5505 - binary_accuracy: 0.7773\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4999 - binary_accuracy: 0.7891\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4987 - binary_accuracy: 0.7832\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5649 - binary_accuracy: 0.7871\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5325 - binary_accuracy: 0.7969\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5639 - binary_accuracy: 0.7832\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5944 - binary_accuracy: 0.7773\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5601 - binary_accuracy: 0.8125\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5252 - binary_accuracy: 0.8125\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4860 - binary_accuracy: 0.8047\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4850 - binary_accuracy: 0.8066\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5005 - binary_accuracy: 0.7988\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5725 - binary_accuracy: 0.8125\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5173 - binary_accuracy: 0.7969\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5123 - binary_accuracy: 0.8105\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5712 - binary_accuracy: 0.7891\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5511 - binary_accuracy: 0.7949\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5104 - binary_accuracy: 0.8301\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4503 - binary_accuracy: 0.8125\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5393 - binary_accuracy: 0.7852\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5544 - binary_accuracy: 0.7910\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5415 - binary_accuracy: 0.8223\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5230 - binary_accuracy: 0.8027\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4570 - binary_accuracy: 0.8105\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5118 - binary_accuracy: 0.8086\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4960 - binary_accuracy: 0.7988\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4507 - binary_accuracy: 0.8379\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5821 - binary_accuracy: 0.8242\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5899 - binary_accuracy: 0.8145\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.8125\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5122 - binary_accuracy: 0.8203\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4920 - binary_accuracy: 0.8066\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4897 - binary_accuracy: 0.8184\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4909 - binary_accuracy: 0.8184\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4301 - binary_accuracy: 0.8359\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4213 - binary_accuracy: 0.8379\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4704 - binary_accuracy: 0.8398\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3960 - binary_accuracy: 0.8574\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4642 - binary_accuracy: 0.8223\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7537 - binary_accuracy: 0.8262\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7372 - binary_accuracy: 0.8145\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5471 - binary_accuracy: 0.8281\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4539 - binary_accuracy: 0.8203\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6383 - binary_accuracy: 0.8418\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6327 - binary_accuracy: 0.8184\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5450 - binary_accuracy: 0.8301\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5812 - binary_accuracy: 0.8379\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5230 - binary_accuracy: 0.8359\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4515 - binary_accuracy: 0.8359\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4300 - binary_accuracy: 0.8457\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4605 - binary_accuracy: 0.8418\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6627 - binary_accuracy: 0.8086\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6859 - binary_accuracy: 0.8105\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5126 - binary_accuracy: 0.8262\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5744 - binary_accuracy: 0.8398\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6727 - binary_accuracy: 0.8086\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4246 - binary_accuracy: 0.8438\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6432 - binary_accuracy: 0.8613\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5548 - binary_accuracy: 0.8242\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6092 - binary_accuracy: 0.8223\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5176 - binary_accuracy: 0.8184\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5688 - binary_accuracy: 0.8535\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7698 - binary_accuracy: 0.8164\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7133 - binary_accuracy: 0.8320\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7619 - binary_accuracy: 0.8340\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6350 - binary_accuracy: 0.8164\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6438 - binary_accuracy: 0.8516\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5058 - binary_accuracy: 0.8457\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7370 - binary_accuracy: 0.8301\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5227 - binary_accuracy: 0.8438\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8416 - binary_accuracy: 0.8457\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6516 - binary_accuracy: 0.8418\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4893 - binary_accuracy: 0.8477\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6363 - binary_accuracy: 0.8555\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5723 - binary_accuracy: 0.8340\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6478 - binary_accuracy: 0.8398\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6775 - binary_accuracy: 0.8281\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6583 - binary_accuracy: 0.8398\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5291 - binary_accuracy: 0.8516\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4359 - binary_accuracy: 0.8477\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4354 - binary_accuracy: 0.8711\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5268 - binary_accuracy: 0.8652\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5904 - binary_accuracy: 0.8457\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5156 - binary_accuracy: 0.8242\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5139 - binary_accuracy: 0.8496\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5639 - binary_accuracy: 0.8418\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.4349 - binary_accuracy: 0.5469\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6816 - binary_accuracy: 0.6367\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6322 - binary_accuracy: 0.6621\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5966 - binary_accuracy: 0.6875\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5677 - binary_accuracy: 0.7441\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5273 - binary_accuracy: 0.7441\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5452 - binary_accuracy: 0.7422\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5035 - binary_accuracy: 0.7734\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5111 - binary_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6041 - binary_accuracy: 0.7715\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5915 - binary_accuracy: 0.7656\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8209 - binary_accuracy: 0.7227\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5694 - binary_accuracy: 0.7852\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5094 - binary_accuracy: 0.8125\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5769 - binary_accuracy: 0.7910\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4931 - binary_accuracy: 0.8359\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6660 - binary_accuracy: 0.8105\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5927 - binary_accuracy: 0.7695\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6525 - binary_accuracy: 0.8145\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5648 - binary_accuracy: 0.8242\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5960 - binary_accuracy: 0.8086\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7956 - binary_accuracy: 0.8145\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5478 - binary_accuracy: 0.8652\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9237 - binary_accuracy: 0.8184\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5102 - binary_accuracy: 0.8320\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7960 - binary_accuracy: 0.8223\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7786 - binary_accuracy: 0.8105\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7405 - binary_accuracy: 0.8223\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4202 - binary_accuracy: 0.8535\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7921 - binary_accuracy: 0.8125\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7470 - binary_accuracy: 0.8477\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6089 - binary_accuracy: 0.8262\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7039 - binary_accuracy: 0.8398\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4682 - binary_accuracy: 0.8281\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5088 - binary_accuracy: 0.8574\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4421 - binary_accuracy: 0.8359\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8387 - binary_accuracy: 0.8535\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6008 - binary_accuracy: 0.8438\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4341 - binary_accuracy: 0.8340\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7468 - binary_accuracy: 0.8477\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6259 - binary_accuracy: 0.8516\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4010 - binary_accuracy: 0.8613\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5768 - binary_accuracy: 0.8164\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4776 - binary_accuracy: 0.8535\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5007 - binary_accuracy: 0.8691\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6757 - binary_accuracy: 0.8574\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5903 - binary_accuracy: 0.8164\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5039 - binary_accuracy: 0.8145\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3940 - binary_accuracy: 0.8418\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4081 - binary_accuracy: 0.8672\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4784 - binary_accuracy: 0.8555\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9737 - binary_accuracy: 0.8477\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5181 - binary_accuracy: 0.8418\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8640 - binary_accuracy: 0.8418\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3376 - binary_accuracy: 0.8398\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7378 - binary_accuracy: 0.8418\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4700 - binary_accuracy: 0.8398\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8905 - binary_accuracy: 0.8359\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7026 - binary_accuracy: 0.8652\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5010 - binary_accuracy: 0.8398\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7179 - binary_accuracy: 0.8633\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6901 - binary_accuracy: 0.8516\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6316 - binary_accuracy: 0.8457\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5375 - binary_accuracy: 0.8574\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8460 - binary_accuracy: 0.8496\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4019 - binary_accuracy: 0.8574\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5056 - binary_accuracy: 0.8477\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1790 - binary_accuracy: 0.8438\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9695 - binary_accuracy: 0.8379\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0341 - binary_accuracy: 0.8516\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5999 - binary_accuracy: 0.8672\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6574 - binary_accuracy: 0.8477\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9510 - binary_accuracy: 0.8477\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5735 - binary_accuracy: 0.8496\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9905 - binary_accuracy: 0.8535\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3966 - binary_accuracy: 0.8574\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8893 - binary_accuracy: 0.8496\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1956 - binary_accuracy: 0.8496\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.7362 - binary_accuracy: 0.8711\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8282 - binary_accuracy: 0.8340\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7171 - binary_accuracy: 0.8691\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8656 - binary_accuracy: 0.8379\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9603 - binary_accuracy: 0.8457\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7214 - binary_accuracy: 0.8613\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0790 - binary_accuracy: 0.8438\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5018 - binary_accuracy: 0.8633\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4848 - binary_accuracy: 0.8477\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3845 - binary_accuracy: 0.8594\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8999 - binary_accuracy: 0.8770\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8493 - binary_accuracy: 0.8848\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6336 - binary_accuracy: 0.8242\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - binary_accuracy: 0.8516\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5536 - binary_accuracy: 0.8594\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5739 - binary_accuracy: 0.8691\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0349 - binary_accuracy: 0.8379\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4413 - binary_accuracy: 0.8652\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4713 - binary_accuracy: 0.8574\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4112 - binary_accuracy: 0.8652\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8823 - binary_accuracy: 0.8613\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3745 - binary_accuracy: 0.8633\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.5529 - binary_accuracy: 0.5742\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8057 - binary_accuracy: 0.6113\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6860 - binary_accuracy: 0.6191\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6612 - binary_accuracy: 0.6504\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6907 - binary_accuracy: 0.6699\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6571 - binary_accuracy: 0.6348\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6926 - binary_accuracy: 0.6992\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6827 - binary_accuracy: 0.6719\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6173 - binary_accuracy: 0.6719\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6647 - binary_accuracy: 0.6777\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6388 - binary_accuracy: 0.7070\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7162 - binary_accuracy: 0.7051\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5809 - binary_accuracy: 0.7285\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5842 - binary_accuracy: 0.7383\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.7383\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5742 - binary_accuracy: 0.7637\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6428 - binary_accuracy: 0.7480\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5722 - binary_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6112 - binary_accuracy: 0.7422\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6800 - binary_accuracy: 0.7520\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5740 - binary_accuracy: 0.7773\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5510 - binary_accuracy: 0.7793\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4583 - binary_accuracy: 0.8086\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6245 - binary_accuracy: 0.7773\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6335 - binary_accuracy: 0.7852\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4931 - binary_accuracy: 0.8027\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5508 - binary_accuracy: 0.7891\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7832 - binary_accuracy: 0.8008\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7211 - binary_accuracy: 0.7949\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4808 - binary_accuracy: 0.7910\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7124 - binary_accuracy: 0.8027\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4783 - binary_accuracy: 0.8398\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4999 - binary_accuracy: 0.8125\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6525 - binary_accuracy: 0.8008\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7026 - binary_accuracy: 0.8047\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4809 - binary_accuracy: 0.8262\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4523 - binary_accuracy: 0.8164\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5271 - binary_accuracy: 0.8105\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6115 - binary_accuracy: 0.8145\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6977 - binary_accuracy: 0.8379\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5670 - binary_accuracy: 0.8477\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4162 - binary_accuracy: 0.8398\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4902 - binary_accuracy: 0.8301\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5561 - binary_accuracy: 0.8418\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4427 - binary_accuracy: 0.8418\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5930 - binary_accuracy: 0.8574\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4657 - binary_accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4500 - binary_accuracy: 0.8262\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4733 - binary_accuracy: 0.8457\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5810 - binary_accuracy: 0.8223\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4105 - binary_accuracy: 0.8633\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4180 - binary_accuracy: 0.8613\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8321 - binary_accuracy: 0.8301\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6423 - binary_accuracy: 0.8711\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6277 - binary_accuracy: 0.8613\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4368 - binary_accuracy: 0.8281\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0846 - binary_accuracy: 0.8340\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3576 - binary_accuracy: 0.8770\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5745 - binary_accuracy: 0.8477\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1771 - binary_accuracy: 0.8555\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8685 - binary_accuracy: 0.8633\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6386 - binary_accuracy: 0.8457\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6911 - binary_accuracy: 0.8633\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4114 - binary_accuracy: 0.8730\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4769 - binary_accuracy: 0.8633\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4814 - binary_accuracy: 0.8594\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1905 - binary_accuracy: 0.8691\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6973 - binary_accuracy: 0.8691\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1805 - binary_accuracy: 0.8633\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8571 - binary_accuracy: 0.8672\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1387 - binary_accuracy: 0.8574\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9485 - binary_accuracy: 0.8789\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5503 - binary_accuracy: 0.8652\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3864 - binary_accuracy: 0.8770\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3958 - binary_accuracy: 0.8789\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7329 - binary_accuracy: 0.8652\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6698 - binary_accuracy: 0.8535\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3129 - binary_accuracy: 0.8594\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8258 - binary_accuracy: 0.8750\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7190 - binary_accuracy: 0.8887\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4746 - binary_accuracy: 0.8633\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0597 - binary_accuracy: 0.8789\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.8770\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3826 - binary_accuracy: 0.8652\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.8730\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4799 - binary_accuracy: 0.8770\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4506 - binary_accuracy: 0.8574\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4130 - binary_accuracy: 0.8691\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7091 - binary_accuracy: 0.8926\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0471 - binary_accuracy: 0.8770\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4373 - binary_accuracy: 0.8594\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6793 - binary_accuracy: 0.8594\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4004 - binary_accuracy: 0.8809\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3864 - binary_accuracy: 0.8809\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3742 - binary_accuracy: 0.8730\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4328 - binary_accuracy: 0.8965\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4627 - binary_accuracy: 0.8906\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8278 - binary_accuracy: 0.8809\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6387 - binary_accuracy: 0.8848\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f22c31ca7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.9768 - binary_accuracy: 0.5703\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8500 - binary_accuracy: 0.6543\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7588 - binary_accuracy: 0.7109\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5951 - binary_accuracy: 0.7344\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5925 - binary_accuracy: 0.7207\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6274 - binary_accuracy: 0.7656\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5851 - binary_accuracy: 0.7754\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6061 - binary_accuracy: 0.7715\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8128 - binary_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7741 - binary_accuracy: 0.7754\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8341 - binary_accuracy: 0.7930\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6050 - binary_accuracy: 0.8066\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8025 - binary_accuracy: 0.7676\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6701 - binary_accuracy: 0.7676\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6029 - binary_accuracy: 0.7910\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7784 - binary_accuracy: 0.7637\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.7930\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5877 - binary_accuracy: 0.8008\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5558 - binary_accuracy: 0.8320\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5734 - binary_accuracy: 0.8145\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5469 - binary_accuracy: 0.8086\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4672 - binary_accuracy: 0.8164\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6366 - binary_accuracy: 0.8164\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6109 - binary_accuracy: 0.8008\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6205 - binary_accuracy: 0.7969\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5933 - binary_accuracy: 0.8145\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4715 - binary_accuracy: 0.8301\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7541 - binary_accuracy: 0.7852\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4708 - binary_accuracy: 0.8301\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7729 - binary_accuracy: 0.8105\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6615 - binary_accuracy: 0.7891\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5417 - binary_accuracy: 0.8203\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4864 - binary_accuracy: 0.8145\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5736 - binary_accuracy: 0.7988\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5937 - binary_accuracy: 0.7969\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6035 - binary_accuracy: 0.8398\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5722 - binary_accuracy: 0.8066\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4927 - binary_accuracy: 0.8262\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5617 - binary_accuracy: 0.8320\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6936 - binary_accuracy: 0.8340\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4933 - binary_accuracy: 0.8242\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5131 - binary_accuracy: 0.8418\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4711 - binary_accuracy: 0.8223\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4338 - binary_accuracy: 0.8418\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6441 - binary_accuracy: 0.8105\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5254 - binary_accuracy: 0.8320\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5097 - binary_accuracy: 0.8398\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5544 - binary_accuracy: 0.8281\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6599 - binary_accuracy: 0.8281\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4791 - binary_accuracy: 0.8477\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4385 - binary_accuracy: 0.8848\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7248 - binary_accuracy: 0.8496\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.3154 - binary_accuracy: 0.8359\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7524 - binary_accuracy: 0.8691\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0000 - binary_accuracy: 0.8438\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6327 - binary_accuracy: 0.8770\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8065 - binary_accuracy: 0.8809\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0952 - binary_accuracy: 0.8535\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6583 - binary_accuracy: 0.8750\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3083 - binary_accuracy: 0.8613\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.2107 - binary_accuracy: 0.8809\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0583 - binary_accuracy: 0.8672\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5098 - binary_accuracy: 0.8789\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6863 - binary_accuracy: 0.8770\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5186 - binary_accuracy: 0.8770\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6846 - binary_accuracy: 0.8672\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8197 - binary_accuracy: 0.8750\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8351 - binary_accuracy: 0.8633\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1995 - binary_accuracy: 0.8535\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.6448 - binary_accuracy: 0.8516\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3387 - binary_accuracy: 0.8574\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0806 - binary_accuracy: 0.8535\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7692 - binary_accuracy: 0.8770\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7357 - binary_accuracy: 0.8613\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7772 - binary_accuracy: 0.8477\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5755 - binary_accuracy: 0.8418\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5233 - binary_accuracy: 0.8730\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5295 - binary_accuracy: 0.8730\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4905 - binary_accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4315 - binary_accuracy: 0.8770\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0145 - binary_accuracy: 0.8730\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1520 - binary_accuracy: 0.8594\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1235 - binary_accuracy: 0.8613\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3891 - binary_accuracy: 0.8730\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7289 - binary_accuracy: 0.8789\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3626 - binary_accuracy: 0.8789\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0189 - binary_accuracy: 0.8848\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8139 - binary_accuracy: 0.8750\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5048 - binary_accuracy: 0.8652\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8556 - binary_accuracy: 0.8691\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2086 - binary_accuracy: 0.8848\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9250 - binary_accuracy: 0.8711\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4343 - binary_accuracy: 0.8887\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7303 - binary_accuracy: 0.8789\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3708 - binary_accuracy: 0.8809\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.7468 - binary_accuracy: 0.8750\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0871 - binary_accuracy: 0.8828\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1314 - binary_accuracy: 0.8652\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2619 - binary_accuracy: 0.8809\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2937 - binary_accuracy: 0.8867\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f22c2fede60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.5150 - binary_accuracy: 0.5801\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6268 - binary_accuracy: 0.6250\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5637 - binary_accuracy: 0.6289\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5853 - binary_accuracy: 0.6367\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5369 - binary_accuracy: 0.6641\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5169 - binary_accuracy: 0.6855\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5938 - binary_accuracy: 0.7031\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5854 - binary_accuracy: 0.7246\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5385 - binary_accuracy: 0.7422\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5123 - binary_accuracy: 0.7461\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6831 - binary_accuracy: 0.7930\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6978 - binary_accuracy: 0.7637\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5869 - binary_accuracy: 0.7734\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6872 - binary_accuracy: 0.7559\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5386 - binary_accuracy: 0.8086\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6522 - binary_accuracy: 0.7988\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5359 - binary_accuracy: 0.8027\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6223 - binary_accuracy: 0.8125\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8124 - binary_accuracy: 0.8047\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6355 - binary_accuracy: 0.8242\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5737 - binary_accuracy: 0.8203\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5303 - binary_accuracy: 0.8223\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5062 - binary_accuracy: 0.7910\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6459 - binary_accuracy: 0.8555\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5601 - binary_accuracy: 0.8477\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6746 - binary_accuracy: 0.8320\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6762 - binary_accuracy: 0.8281\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5485 - binary_accuracy: 0.8457\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4870 - binary_accuracy: 0.8496\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5440 - binary_accuracy: 0.8340\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8557 - binary_accuracy: 0.8379\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9163 - binary_accuracy: 0.8066\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5359 - binary_accuracy: 0.8145\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5209 - binary_accuracy: 0.8477\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6337 - binary_accuracy: 0.8105\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6045 - binary_accuracy: 0.8398\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4609 - binary_accuracy: 0.8516\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5759 - binary_accuracy: 0.8535\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6661 - binary_accuracy: 0.8438\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4789 - binary_accuracy: 0.8516\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7329 - binary_accuracy: 0.8496\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1019 - binary_accuracy: 0.8652\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7002 - binary_accuracy: 0.8555\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1146 - binary_accuracy: 0.8711\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7257 - binary_accuracy: 0.8926\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3906 - binary_accuracy: 0.8320\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8873 - binary_accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8190 - binary_accuracy: 0.8398\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7432 - binary_accuracy: 0.8594\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6368 - binary_accuracy: 0.8633\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2288 - binary_accuracy: 0.8496\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0094 - binary_accuracy: 0.8477\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.1874 - binary_accuracy: 0.8711\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6339 - binary_accuracy: 0.8613\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7454 - binary_accuracy: 0.8750\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4604 - binary_accuracy: 0.8828\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9355 - binary_accuracy: 0.8613\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6649 - binary_accuracy: 0.8691\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6038 - binary_accuracy: 0.8691\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0293 - binary_accuracy: 0.8633\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5401 - binary_accuracy: 0.8730\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0659 - binary_accuracy: 0.8633\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9193 - binary_accuracy: 0.8652\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5282 - binary_accuracy: 0.8672\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8182 - binary_accuracy: 0.8672\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4840 - binary_accuracy: 0.8691\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7285 - binary_accuracy: 0.8672\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0029 - binary_accuracy: 0.8672\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8509 - binary_accuracy: 0.8750\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9018 - binary_accuracy: 0.8906\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2173 - binary_accuracy: 0.8711\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2399 - binary_accuracy: 0.8613\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5596 - binary_accuracy: 0.8770\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4264 - binary_accuracy: 0.8711\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2863 - binary_accuracy: 0.8555\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8781 - binary_accuracy: 0.8613\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8148 - binary_accuracy: 0.8594\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5565 - binary_accuracy: 0.8516\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1807 - binary_accuracy: 0.8652\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7380 - binary_accuracy: 0.8809\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6300 - binary_accuracy: 0.8730\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9040 - binary_accuracy: 0.8652\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4990 - binary_accuracy: 0.8789\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0755 - binary_accuracy: 0.8770\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5889 - binary_accuracy: 0.8750\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3874 - binary_accuracy: 0.8945\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0295 - binary_accuracy: 0.8848\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0726 - binary_accuracy: 0.8750\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6416 - binary_accuracy: 0.8574\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9313 - binary_accuracy: 0.8867\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6986 - binary_accuracy: 0.8398\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6368 - binary_accuracy: 0.8770\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.3947 - binary_accuracy: 0.8652\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8564 - binary_accuracy: 0.8594\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6090 - binary_accuracy: 0.8652\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9885 - binary_accuracy: 0.8906\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2010 - binary_accuracy: 0.8926\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8657 - binary_accuracy: 0.8652\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7450 - binary_accuracy: 0.8730\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2804 - binary_accuracy: 0.8867\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.5339 - binary_accuracy: 0.5430\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6774 - binary_accuracy: 0.5996\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6059 - binary_accuracy: 0.6465\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5726 - binary_accuracy: 0.6738\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5315 - binary_accuracy: 0.6797\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5367 - binary_accuracy: 0.7324\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.7285\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5434 - binary_accuracy: 0.7109\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6072 - binary_accuracy: 0.7266\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6198 - binary_accuracy: 0.7598\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.7480\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6265 - binary_accuracy: 0.7578\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.7520\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5528 - binary_accuracy: 0.7754\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5129 - binary_accuracy: 0.8027\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5042 - binary_accuracy: 0.8438\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5347 - binary_accuracy: 0.8027\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6215 - binary_accuracy: 0.8438\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4838 - binary_accuracy: 0.8125\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4569 - binary_accuracy: 0.8398\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5243 - binary_accuracy: 0.8320\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5631 - binary_accuracy: 0.8281\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4329 - binary_accuracy: 0.8574\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5403 - binary_accuracy: 0.8145\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.8340\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5661 - binary_accuracy: 0.8359\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4591 - binary_accuracy: 0.8359\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8105 - binary_accuracy: 0.8438\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5826 - binary_accuracy: 0.8398\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6080 - binary_accuracy: 0.8398\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6378 - binary_accuracy: 0.8281\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8289 - binary_accuracy: 0.8457\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6548 - binary_accuracy: 0.8496\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7216 - binary_accuracy: 0.8457\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4796 - binary_accuracy: 0.8555\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5819 - binary_accuracy: 0.8301\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5020 - binary_accuracy: 0.8555\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6276 - binary_accuracy: 0.8418\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9944 - binary_accuracy: 0.8340\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6699 - binary_accuracy: 0.8574\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4855 - binary_accuracy: 0.8457\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5446 - binary_accuracy: 0.8555\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.8496\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8944 - binary_accuracy: 0.8359\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6340 - binary_accuracy: 0.8340\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5762 - binary_accuracy: 0.8320\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5236 - binary_accuracy: 0.8672\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4579 - binary_accuracy: 0.8672\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4515 - binary_accuracy: 0.8574\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6882 - binary_accuracy: 0.8770\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6004 - binary_accuracy: 0.8867\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6370 - binary_accuracy: 0.8555\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5794 - binary_accuracy: 0.8672\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8964 - binary_accuracy: 0.8496\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5892 - binary_accuracy: 0.8711\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4470 - binary_accuracy: 0.8672\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6712 - binary_accuracy: 0.8457\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5172 - binary_accuracy: 0.8789\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4883 - binary_accuracy: 0.8887\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0940 - binary_accuracy: 0.8730\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7572 - binary_accuracy: 0.8555\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0210 - binary_accuracy: 0.8438\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7061 - binary_accuracy: 0.8750\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.9170 - binary_accuracy: 0.8828\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8182 - binary_accuracy: 0.8633\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0515 - binary_accuracy: 0.8730\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6424 - binary_accuracy: 0.8652\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3067 - binary_accuracy: 0.8887\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4801 - binary_accuracy: 0.8887\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9821 - binary_accuracy: 0.8809\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6705 - binary_accuracy: 0.8848\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5212 - binary_accuracy: 0.8789\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5454 - binary_accuracy: 0.8867\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4599 - binary_accuracy: 0.8672\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6128 - binary_accuracy: 0.8809\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.2574 - binary_accuracy: 0.8906\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.3302 - binary_accuracy: 0.8789\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8282 - binary_accuracy: 0.8828\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0150 - binary_accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0733 - binary_accuracy: 0.8594\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6774 - binary_accuracy: 0.8574\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1249 - binary_accuracy: 0.8691\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9804 - binary_accuracy: 0.8848\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0101 - binary_accuracy: 0.8691\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.9709 - binary_accuracy: 0.8867\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7311 - binary_accuracy: 0.8945\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5941 - binary_accuracy: 0.8926\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7433 - binary_accuracy: 0.8711\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7882 - binary_accuracy: 0.8867\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.5172 - binary_accuracy: 0.8652\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2066 - binary_accuracy: 0.8770\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6689 - binary_accuracy: 0.8652\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6247 - binary_accuracy: 0.8984\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4515 - binary_accuracy: 0.8848\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3663 - binary_accuracy: 0.8652\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0212 - binary_accuracy: 0.8613\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.7308 - binary_accuracy: 0.8574\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3654 - binary_accuracy: 0.8652\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9902 - binary_accuracy: 0.8750\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4795 - binary_accuracy: 0.8906\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 1.3595 - binary_accuracy: 0.5527\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6630 - binary_accuracy: 0.6348\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5748 - binary_accuracy: 0.6562\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6285 - binary_accuracy: 0.6621\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5668 - binary_accuracy: 0.6641\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6491 - binary_accuracy: 0.6562\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6245 - binary_accuracy: 0.6875\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5649 - binary_accuracy: 0.7070\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5721 - binary_accuracy: 0.7090\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5469 - binary_accuracy: 0.7422\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6204 - binary_accuracy: 0.7285\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5228 - binary_accuracy: 0.7617\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5545 - binary_accuracy: 0.7695\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5752 - binary_accuracy: 0.7695\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.7793\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5681 - binary_accuracy: 0.7578\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5478 - binary_accuracy: 0.7734\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5545 - binary_accuracy: 0.7617\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4714 - binary_accuracy: 0.8086\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5324 - binary_accuracy: 0.7773\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5047 - binary_accuracy: 0.7793\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5683 - binary_accuracy: 0.7930\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6570 - binary_accuracy: 0.7812\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5075 - binary_accuracy: 0.7969\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5865 - binary_accuracy: 0.7910\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5690 - binary_accuracy: 0.7715\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5516 - binary_accuracy: 0.8105\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5683 - binary_accuracy: 0.7773\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8387 - binary_accuracy: 0.7852\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6742 - binary_accuracy: 0.7949\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4801 - binary_accuracy: 0.8223\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5114 - binary_accuracy: 0.8008\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5392 - binary_accuracy: 0.8027\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7206 - binary_accuracy: 0.7793\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5910 - binary_accuracy: 0.8164\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6234 - binary_accuracy: 0.8223\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6304 - binary_accuracy: 0.7715\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5498 - binary_accuracy: 0.7949\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8215 - binary_accuracy: 0.8047\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6572 - binary_accuracy: 0.7930\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4737 - binary_accuracy: 0.8203\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4760 - binary_accuracy: 0.8105\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4396 - binary_accuracy: 0.8145\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5311 - binary_accuracy: 0.8281\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5623 - binary_accuracy: 0.8047\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5276 - binary_accuracy: 0.8203\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5140 - binary_accuracy: 0.8125\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6419 - binary_accuracy: 0.8066\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4887 - binary_accuracy: 0.8066\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6534 - binary_accuracy: 0.8086\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4612 - binary_accuracy: 0.8203\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7393 - binary_accuracy: 0.7969\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5087 - binary_accuracy: 0.8184\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4354 - binary_accuracy: 0.8242\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5420 - binary_accuracy: 0.8223\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4267 - binary_accuracy: 0.8320\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8262\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4361 - binary_accuracy: 0.8164\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5839 - binary_accuracy: 0.7832\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4511 - binary_accuracy: 0.8301\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5216 - binary_accuracy: 0.8125\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4886 - binary_accuracy: 0.8398\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5275 - binary_accuracy: 0.8223\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4397 - binary_accuracy: 0.8301\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4629 - binary_accuracy: 0.8320\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7758 - binary_accuracy: 0.8223\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7270 - binary_accuracy: 0.8203\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8097 - binary_accuracy: 0.8262\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5427 - binary_accuracy: 0.8516\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7680 - binary_accuracy: 0.8203\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7683 - binary_accuracy: 0.8184\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4135 - binary_accuracy: 0.8418\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6370 - binary_accuracy: 0.8457\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4387 - binary_accuracy: 0.8359\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9062 - binary_accuracy: 0.8516\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6047 - binary_accuracy: 0.8262\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5120 - binary_accuracy: 0.8301\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4954 - binary_accuracy: 0.8398\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4290 - binary_accuracy: 0.8340\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4609 - binary_accuracy: 0.8320\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5243 - binary_accuracy: 0.8242\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8685 - binary_accuracy: 0.8203\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7056 - binary_accuracy: 0.8203\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4942 - binary_accuracy: 0.8398\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8102 - binary_accuracy: 0.8379\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8012 - binary_accuracy: 0.8242\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7073 - binary_accuracy: 0.8301\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4972 - binary_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6667 - binary_accuracy: 0.8008\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5799 - binary_accuracy: 0.8262\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8023 - binary_accuracy: 0.8164\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5540 - binary_accuracy: 0.8281\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5246 - binary_accuracy: 0.8281\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9437 - binary_accuracy: 0.8164\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4624 - binary_accuracy: 0.8418\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4366 - binary_accuracy: 0.8398\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6677 - binary_accuracy: 0.8320\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5245 - binary_accuracy: 0.8242\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4600 - binary_accuracy: 0.8359\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5552 - binary_accuracy: 0.8477\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 1s 2ms/step - loss: 2.4818 - binary_accuracy: 0.5458\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7883 - binary_accuracy: 0.5731\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6647 - binary_accuracy: 0.6433\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7352 - binary_accuracy: 0.6628\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6344 - binary_accuracy: 0.6745\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6024 - binary_accuracy: 0.6725\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6365 - binary_accuracy: 0.6764\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6669 - binary_accuracy: 0.6667\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6551 - binary_accuracy: 0.7135\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6295 - binary_accuracy: 0.7154\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6405 - binary_accuracy: 0.7563\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6590 - binary_accuracy: 0.7018\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6457 - binary_accuracy: 0.7212\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6339 - binary_accuracy: 0.6823\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7036 - binary_accuracy: 0.7310\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6193 - binary_accuracy: 0.7193\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6678 - binary_accuracy: 0.7096\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6425 - binary_accuracy: 0.7251\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6520 - binary_accuracy: 0.7115\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5553 - binary_accuracy: 0.7368\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5890 - binary_accuracy: 0.7544\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5369 - binary_accuracy: 0.7544\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6405 - binary_accuracy: 0.7602\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6165 - binary_accuracy: 0.7797\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6568 - binary_accuracy: 0.7427\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5441 - binary_accuracy: 0.7622\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7402 - binary_accuracy: 0.7485\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5776 - binary_accuracy: 0.7641\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4974 - binary_accuracy: 0.7758\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7128 - binary_accuracy: 0.7563\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5744 - binary_accuracy: 0.7700\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5541 - binary_accuracy: 0.7661\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.7739\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5750 - binary_accuracy: 0.7934\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4972 - binary_accuracy: 0.8051\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5669 - binary_accuracy: 0.7914\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5834 - binary_accuracy: 0.7914\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8146 - binary_accuracy: 0.7973\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6736 - binary_accuracy: 0.8012\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4332 - binary_accuracy: 0.8382\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5489 - binary_accuracy: 0.8226\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5521 - binary_accuracy: 0.8129\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7442 - binary_accuracy: 0.7973\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4518 - binary_accuracy: 0.8285\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5270 - binary_accuracy: 0.8051\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8109 - binary_accuracy: 0.8265\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4472 - binary_accuracy: 0.8363\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.3791 - binary_accuracy: 0.8596\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5064 - binary_accuracy: 0.8304\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.3549 - binary_accuracy: 0.8324\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6674 - binary_accuracy: 0.8480\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5470 - binary_accuracy: 0.8324\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6777 - binary_accuracy: 0.8402\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3494 - binary_accuracy: 0.8772\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7762 - binary_accuracy: 0.8460\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4425 - binary_accuracy: 0.8519\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7087 - binary_accuracy: 0.8558\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.8781 - binary_accuracy: 0.8499\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6667 - binary_accuracy: 0.8421\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9964 - binary_accuracy: 0.8655\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.1630 - binary_accuracy: 0.8558\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7792 - binary_accuracy: 0.8596\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6446 - binary_accuracy: 0.8655\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.9046 - binary_accuracy: 0.8538\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.7254 - binary_accuracy: 0.8635\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.0082 - binary_accuracy: 0.8674\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7114 - binary_accuracy: 0.8596\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4712 - binary_accuracy: 0.8519\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3701 - binary_accuracy: 0.8499\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5569 - binary_accuracy: 0.8772\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.9963 - binary_accuracy: 0.8519\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5108 - binary_accuracy: 0.8596\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5125 - binary_accuracy: 0.8733\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.7774 - binary_accuracy: 0.8519\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4212 - binary_accuracy: 0.8733\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.4978 - binary_accuracy: 0.8519\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4369 - binary_accuracy: 0.8635\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 3.5511 - binary_accuracy: 0.8499\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.4445 - binary_accuracy: 0.8655\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7889 - binary_accuracy: 0.8558\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3171 - binary_accuracy: 0.8363\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.1762 - binary_accuracy: 0.8343\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5715 - binary_accuracy: 0.8635\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7938 - binary_accuracy: 0.8655\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.3547 - binary_accuracy: 0.8519\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.7451 - binary_accuracy: 0.8421\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.9471 - binary_accuracy: 0.8519\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 3.3196 - binary_accuracy: 0.8343\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 3.8657 - binary_accuracy: 0.8421\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.3542 - binary_accuracy: 0.8596\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.6295 - binary_accuracy: 0.8343\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8989 - binary_accuracy: 0.8694\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.6928 - binary_accuracy: 0.8343\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.6871 - binary_accuracy: 0.8538\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.9456 - binary_accuracy: 0.8519\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.3900 - binary_accuracy: 0.8382\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.8714 - binary_accuracy: 0.8850\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 1.6593 - binary_accuracy: 0.8499\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.4465 - binary_accuracy: 0.8655\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 2.6194 - binary_accuracy: 0.8421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXey-NGAjsu6",
        "outputId": "71a2696b-03fb-4f5b-e341-f133a9d224d3"
      },
      "source": [
        "resultados"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66666667, 0.89473684, 0.9122807 , 0.80701754, 0.89473684,\n",
              "       0.96491228, 0.87719298, 0.94736842, 0.8245614 , 0.83928571])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVsadGaBjzA6",
        "outputId": "ab234f31-da0d-4215-9b30-aa808741109f"
      },
      "source": [
        "media = resultados.mean()\n",
        "media\n",
        "#media sem o dropout (0.7924185463659148)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8628759398496241"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynr5Hm8Kj9Fe",
        "outputId": "f2b31058-0930-401c-d424-4307b47b182b"
      },
      "source": [
        "#Quantos valores estão variando em relação a média (0.79)\n",
        "# Quanto maior o valor maior a probabilidade de overfitting\n",
        "desvio= resultados.std()\n",
        "desvio\n",
        "#desvio sem o dropout (0.08553035509662345)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08115982894881578"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}